{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GDE+NasBench101",
      "provenance": [],
      "collapsed_sections": [
        "LGWYcVzqR7u-",
        "FB1HP88VV1z7",
        "q6GcFl-7V__U",
        "majhg_V8WRWI",
        "jU82B_9avthm"
      ],
      "authorship_tag": "ABX9TyNjddaeTpICnhrOk8LC8Ps3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Multi-Objective-NAS/invertible-nas-algorithm/blob/master/GDE%2BNasBench101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0uTqCujPcZx",
        "colab_type": "text"
      },
      "source": [
        "#Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY6utA-AEDkP",
        "colab_type": "code",
        "outputId": "868245fe-f503-454b-bce5-3af24927909b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "!git clone https://github.com/Zymrael/gde\n",
        "!git submodule init\n",
        "!git submodule update"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gde'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 67 (delta 29), reused 29 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufyH4uMRT5q1",
        "colab_type": "code",
        "outputId": "e268e0ad-8497-4cd0-8150-985fe04f43ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "!pip install dgl-cu101"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/42/3207329b65dbd179d5c5528c3bc4f1963763c7072f8f1718597365d28981/dgl_cu101-0.4.2-cp36-cp36m-manylinux1_x86_64.whl (16.2MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2MB 201kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (2.4)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (1.18.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl-cu101) (4.4.2)\n",
            "Installing collected packages: dgl-cu101\n",
            "Successfully installed dgl-cu101-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8mLWV7lPQLL",
        "colab_type": "code",
        "outputId": "6bde6e12-8fac-489d-85d4-fe2ded77ab8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "!pip install git+https://github.com/rtqichen/torchdiffeq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rtqichen/torchdiffeq\n",
            "  Cloning https://github.com/rtqichen/torchdiffeq to /tmp/pip-req-build-2pdj14i9\n",
            "  Running command git clone -q https://github.com/rtqichen/torchdiffeq /tmp/pip-req-build-2pdj14i9\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torchdiffeq==0.0.1) (1.4.0)\n",
            "Building wheels for collected packages: torchdiffeq\n",
            "  Building wheel for torchdiffeq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchdiffeq: filename=torchdiffeq-0.0.1-cp36-none-any.whl size=27578 sha256=f951d56d2362baaa9591c790e332789967cabdaa8882787e80e3b974212227a9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gjgg2xic/wheels/3f/76/69/01867bf3355c3bc8bae7e556b17b44c395b6cda5e76fd8ddc7\n",
            "Successfully built torchdiffeq\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvSUB8hRR3_m",
        "colab_type": "text"
      },
      "source": [
        "#Installation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i06DFfXR22T",
        "colab_type": "code",
        "outputId": "0d6a0283-8bbc-4c9d-bb33-fc1cd44627bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "#!curl -O https://storage.googleapis.com/nasbench/nasbench_full.tfrecord\n",
        "!curl -O https://storage.googleapis.com/nasbench/nasbench_only108.tfrecord\n",
        "# Clone and install the code and dependencies.\n",
        "\n",
        "!git clone https://github.com/google-research/nasbench\n",
        "!pip intall ./nasbench"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  498M  100  498M    0     0  74.7M      0  0:00:06  0:00:06 --:--:-- 65.4M\n",
            "Cloning into 'nasbench'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 96 (delta 0), reused 2 (delta 0), pack-reused 92\u001b[K\n",
            "Unpacking objects: 100% (96/96), done.\n",
            "ERROR: unknown command \"intall\" - maybe you meant \"install\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGWYcVzqR7u-",
        "colab_type": "text"
      },
      "source": [
        "#Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKAh02c7v3ze",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh6xZU7bPbmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "from gde.torchgde import PerformanceContainer, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJfb9TERKpPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dgl\n",
        "import dgl.data\n",
        "import dgl.function as fn\n",
        "import networkx as nx\n",
        "from dgl import DGLGraph\n",
        "from dgl.data.utils import get_download_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA13u_K7BhAf",
        "colab_type": "text"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6wHSd1hJP8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = torch.device('cuda:0')\n",
        "#DEVICE = torch.device('cpu')\n",
        "BATCH_SIZE = 50\n",
        "LR = 0.1\n",
        "NEPOCHS = 1 \n",
        "RTOL = 1e-7\n",
        "ATOL = 1e-9\n",
        "EDGE_NUM = 9\n",
        "\n",
        "INPUT = 'input'\n",
        "OUTPUT = 'output'\n",
        "CONV3X3 = 'conv3x3-bn-relu'\n",
        "CONV1X1 = 'conv1x1-bn-relu'\n",
        "MAXPOOL3X3 = 'maxpool3x3'\n",
        "OUTPUT = 'output'\n",
        "NOOPT = 'noopt'\n",
        "NUM_VERTICES = 7\n",
        "MAX_EDGES = 9\n",
        "EDGE_LABEL = [NOOPT, CONV3X3, CONV1X1, MAXPOOL3X3, OUTPUT]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDVfj4D5SAbf",
        "colab_type": "text"
      },
      "source": [
        "#Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB1HP88VV1z7",
        "colab_type": "text"
      },
      "source": [
        "### Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "57dd8660-f8d7-4fe0-f277-2acafe1d9e31",
        "id": "Xf2P0pwbMXET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "from nasbench import api\n",
        "\n",
        "nasbench_api = api.NASBench('nasbench_only108.tfrecord')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gde/nasbench\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-365b7c21040c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd ../nasbench'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnasbench\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'api'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OevIDSS4X8Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NAGRAPH(object):\n",
        "\n",
        "    def __init__(self, mat, op):\n",
        "        self.mat = mat\n",
        "        self.op = op\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxgUzP7CG4_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "1.  network architecture -> DGLG object\n",
        "2.  node -> feature vector\n",
        "3.  input = (DGLG, feature matrix), output = [accuracy, latency]\n",
        "\"\"\"\n",
        "class DataLoader(object):\n",
        "    def __init__(self, start, end, batchsize=None):\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.cur = start\n",
        "        if batchsize is None:\n",
        "            self.batchsize = end - start\n",
        "        else:\n",
        "            self.batchsize = batchsize\n",
        "        self.size = end - start\n",
        "        self. nasbench_hashkeys = nasbench_api.hash_iterator()\n",
        "\n",
        "    def __run_experiment(self, mat, op):\n",
        "        model_spec = api.ModelSpec(matrix=mat, ops=op)\n",
        "        q = nasbench_api.query(model_spec)\n",
        "        return q['validation_accuracy'], q['training_time']\n",
        "\n",
        "    def next(self):\n",
        "        global nasbench_hashkeys\n",
        "\n",
        "        xset = []\n",
        "        yset = []\n",
        "        if self.cur == self.end:\n",
        "            self.cur = self.end\n",
        "        for idx in range(self.cur, min(self.cur + self.batchsize, self.end)):\n",
        "            hash_val = nasbench_hashkeys[idx]\n",
        "            fixed_stat, _ = nasbench_api.get_metrics_from_hash(hash_val)\n",
        "            mat, op = fixed_stat['module_adjacency'], fixed_stat['module_operations']\n",
        "            x = encode(mat, op)\n",
        "            y = self.__run_experiment(mat, op)\n",
        "            xset.append(x)\n",
        "            yset.append(y)\n",
        "        xset = torch.FloatTensor(xset)\n",
        "        yset = torch.FloatTensor(yset)\n",
        "        return xset, yset\n",
        "\n",
        "\n",
        "def train_val_test_split(batch_size=100, validation_ratio=0.1, test_ratio=0.1):\n",
        "    global nasbench_hashkeys\n",
        "\n",
        "    revised = []\n",
        "    for hash_val in nasbench_hashkeys:\n",
        "        fixed_stat, _ = nasbench_api.get_metrics_from_hash(hash_val)\n",
        "        mat, op = fixed_stat['module_adjacency'], fixed_stat['module_operations']\n",
        "        if np.sum(mat) == EDGE_NUM:\n",
        "            revised.append(hash_val)\n",
        "\n",
        "    total_size = (len(revised) // batch_size) * batch_size\n",
        "    nasbench_hashkeys = revised[: total_size]\n",
        "    val_size = int(total_size * validation_ratio)\n",
        "    test_size = int(total_size * test_ratio)\n",
        "\n",
        "    return DataLoader(val_size+test_size, total_size, batch_size), DataLoader(0, val_size), DataLoader(val_size, val_size+test_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H16SkgkDTk0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "node feature = \n",
        "(node ordering up to 7) + (edge label) * 9\n",
        "'''\n",
        "\n",
        "def encode(mat, ops):\n",
        "    def _sanity_check(idx1, opidx, idx2):\n",
        "        if idx1 not in range(7):\n",
        "            return False\n",
        "        if idx2 not in range(7):\n",
        "            return False\n",
        "        if opidx not in range(4):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    encoded = []\n",
        "    for inbound, outbound in zip(*np.array(mat).nonzero()):\n",
        "        op = ALLOWED_OPS.index(ops[outbound])\n",
        "        assert _sanity_check(inbound, op, outbound)\n",
        "\n",
        "        embed = [0] * EMBED_SIZE\n",
        "        embed[inbound] = 1\n",
        "        embed[7 + op] = 1\n",
        "        embed[7 + len(ALLOWED_OPS) + outbound] = 1\n",
        "\n",
        "        encoded.append(embed)\n",
        "\n",
        "    assert np.array(encoded).shape == (9 , EMBED_SIZE)\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def max_index(output):\n",
        "    # (1, DIM, 18,18)\n",
        "    encoded = []\n",
        "    outputs = [output_ for output_ in output[0]]\n",
        "    \n",
        "    for output in outputs:\n",
        "        embed = [0 for _ in range(EMBED_SIZE)]\n",
        "        inbound, op, outbound = np.argmax(output[:7]), np.argmax(output[7:-7]), np.argmax(output[-7:])\n",
        "        embed[inbound] = 1\n",
        "        embed[7 + op] = 1\n",
        "        embed[7 + len(ALLOWED_OPS) + outbound] = 1\n",
        "        assert np.sum(np.array(embed)) == 3\n",
        "        encoded.append(embed)\n",
        "\n",
        "    assert np.array(encoded).shape == (9, EMBED_SIZE)\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def decode(encoded):\n",
        "    mat = np.zeros((7, 7))\n",
        "    ops = [INPUT] + [CONV3X3 for _ in range(5)] + [OUTPUT]\n",
        "\n",
        "    for embed in encoded:\n",
        "        inbound, op, outbound = np.nonzero(np.array(embed))[0]\n",
        "        op -= 7\n",
        "        outbound -= (7 + len(ALLOWED_OPS))\n",
        "        ops[outbound] = ALLOWED_OPS[op]\n",
        "        if inbound > outbound:\n",
        "            (inbound, outbound) = (outbound, inbound)\n",
        "        elif inbound == outbound:\n",
        "            continue\n",
        "        mat[inbound][outbound] = 1\n",
        "\n",
        "    return mat.tolist(), ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6GcFl-7V__U",
        "colab_type": "text"
      },
      "source": [
        "### Model Architecture Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pJRxXyGPtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "def norm(dim):\n",
        "    return nn.GroupNorm( dim, dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r50bPVRngIPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConcatConv1d(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
        "        super(ConcatConv1d, self).__init__()\n",
        "        self._layer = nn.Conv1d(\n",
        "            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        tt = torch.ones_like(x[:, :1, :]) * t\n",
        "        ttx = torch.cat([tt, x], 1)\n",
        "        return self._layer(ttx)\n",
        "\n",
        "\n",
        "class ODEfunc(nn.Module):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(ODEfunc, self).__init__()\n",
        "        self.norm1 = norm(dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = ConcatConv1d(dim, dim, 3, 1, 1)\n",
        "        self.norm2 = norm(dim)\n",
        "        self.conv2 = ConcatConv1d(dim, dim, 3, 1, 1)\n",
        "        self.norm3 = norm(dim)\n",
        "        self.nfe = 0\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        out = self.norm1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(t, out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(t, out)\n",
        "        out = self.norm3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXc6zDI_SsoG",
        "colab_type": "code",
        "outputId": "8d2ce03d-2627-477f-8b65-b71ac4ce82e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#test\n",
        "a = torch.ones(3, 2)\n",
        "b = torch.zeros(3, 3)\n",
        "torch.cat([a, b], dim=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_XXh0e5GdBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ODEBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, odefunc, method):\n",
        "        super(ODEBlock, self).__init__()\n",
        "        self.odefunc = odefunc\n",
        "        self.integration_time = torch.tensor([0, 1]).float()\n",
        "        self.method = method\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.integration_time = self.integration_time.type_as(x)\n",
        "        #batch_t = T_series[:x.shape[0]]\n",
        "        out = odeint(self.odefunc, x, self.integration_time , rtol=RTOL, atol=ATOL, method = self.method)\n",
        "        return out[1]\n",
        "\n",
        "    @property\n",
        "    def nfe(self):\n",
        "        return self.odefunc.nfe\n",
        "\n",
        "    @nfe.setter\n",
        "    def nfe(self, value):\n",
        "        self.odefunc.nfe = value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83nFNskiGg8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
        "        ret = x.view(-1, shape)\n",
        "        return ret\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "majhg_V8WRWI",
        "colab_type": "text"
      },
      "source": [
        "### Optional Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5opgvqcGqac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunningAverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, momentum=0.99):\n",
        "        self.momentum = momentum\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = None\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        if self.val is None:\n",
        "            self.avg = val\n",
        "        else:\n",
        "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
        "        self.val = val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC9wuSPnHw4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):\n",
        "    initial_learning_rate = LR * batch_size / batch_denom\n",
        "\n",
        "    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]\n",
        "    vals = [initial_learning_rate * decay for decay in decay_rates]\n",
        "\n",
        "    def learning_rate_fn(itr):\n",
        "        lt = [itr < b for b in boundaries] + [True]\n",
        "        i = np.argmax(lt)\n",
        "        return vals[i]\n",
        "\n",
        "    return learning_rate_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol-Bb4xdIEp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(model, dataloader):\n",
        "    datasize = dataloader.end - dataloader.start\n",
        "    x, y = dataloader.next(datasize)\n",
        "    x = torch.FloatTensor(x)\n",
        "    x = x.to(DEVICE)\n",
        "    y = y.numpy()\n",
        "    model._modules['1'].odefunc.nfe = 0\n",
        "    result = model(x).cpu().detach().numpy()\n",
        "    total_correct = np.sum(np.square(result - y))\n",
        "    return total_correct / datasize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZrD_tl5JNBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcbZc8P2WXYl",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvLFLrxbqn0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf7779a8-f204-4ccb-d356-e0312afd22bf"
      },
      "source": [
        "# Test\n",
        "\n",
        "def add(parameters):\n",
        "    a = parameters['a']\n",
        "    b = parameters['b']\n",
        "    if 'c' in parameters:\n",
        "        c = parameters['c']\n",
        "    return a+b\n",
        "\n",
        "def passing():\n",
        "    return {'a': 1, 'b': 2}\n",
        "\n",
        "out = passing()\n",
        "print(add(out))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPJPgpORhaY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self,in_feats:int, out_feats:int, activation:Callable[[torch.Tensor], torch.Tensor],\n",
        "                 dropout:int, bias:bool=True):\n",
        "        super().__init__()\n",
        "        self.g = None\n",
        "        self.weight = nn.Parameter(torch.Tensor(in_feats, out_feats))\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_feats))\n",
        "        else:\n",
        "            self.bias = None\n",
        "        self.activation = activation\n",
        "        if dropout:\n",
        "            self.dropout = nn.Dropout(p=dropout)\n",
        "        else:\n",
        "            self.dropout = 0.\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        g, h = inputs\n",
        "        if not g is None:\n",
        "            self.g = g\n",
        "        if self.dropout:\n",
        "            h = self.dropout(h)\n",
        "        h = torch.mm(h, self.weight)\n",
        "        # normalization by square root of src degree\n",
        "        h = h * ndata['norm']\n",
        "        self.g.ndata['h'] = h\n",
        "        self.g.update_all(fn.copy_src(src='h', out='m'),\n",
        "                          fn.sum(msg='m', out='h'))\n",
        "        h = self.g.ndata.pop('h')\n",
        "        # normalization by square root of dst degree\n",
        "        h = h * ndata['norm']\n",
        "        # bias\n",
        "        if self.bias is not None:\n",
        "            h = h + self.bias\n",
        "        if self.activation:\n",
        "            h = self.activation(h)\n",
        "        return g, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_zUJZ3DliVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GDEFunc(nn.Module):\n",
        "    def __init__(self, gnn:nn.Module):\n",
        "        \"\"\"General GDE function class. To be passed to an ODEBlock\"\"\"\n",
        "        super().__init__()\n",
        "        self.gnn = gnn\n",
        "        self.nfe = 0\n",
        "    \n",
        "    def set_graph(self, g:dgl.DGLGraph):\n",
        "        for layer in self.gnn:\n",
        "            layer.g = g\n",
        "            \n",
        "    def forward(self, t, h):\n",
        "        self.nfe += 1\n",
        "        , out = self.gnn((None, h))\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngM033v2ljW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ODEBlock(nn.Module):\n",
        "    def __init__(self, odefunc:nn.Module, method:str='dopri5', rtol:float=1e-3, atol:float=1e-4, adjoint:bool=True):\n",
        "        \"\"\" Standard ODEBlock class. Can handle all types of ODE functions\n",
        "            :method:str = {'euler', 'rk4', 'dopri5', 'adams'}\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.odefunc = odefunc\n",
        "        self.method = method\n",
        "        self.adjoint_flag = adjoint\n",
        "        self.atol, self.rtol = atol, rtol\n",
        "\n",
        "    def forward(self, inputs, T:int=1):\n",
        "        g, h = inputs\n",
        "\n",
        "        self.integration_time = torch.tensor([0, T]).float()\n",
        "        self.integration_time = self.integration_time.type_as(h)\n",
        "        \n",
        "        odefunc.set_graph(g)\n",
        "\n",
        "        if self.adjoint_flag:\n",
        "            out = torchdiffeq.odeint_adjoint(self.odefunc, h, self.integration_time,\n",
        "                                             rtol=self.rtol, atol=self.atol, method=self.method)\n",
        "        else:\n",
        "            out = torchdiffeq.odeint(self.odefunc, h, self.integration_time,\n",
        "                                     rtol=self.rtol, atol=self.atol, method=self.method)\n",
        "            \n",
        "        return g, out[-1]\n",
        "    \n",
        "    def forward_batched(self, inputs, nn:int, indices:list, timestamps:set):\n",
        "        \"\"\" Modified forward for ODE batches with different integration times \"\"\"\n",
        "        g, h = inputs\n",
        "\n",
        "        timestamps = torch.Tensor(list(timestamps))\n",
        "\n",
        "        odefunc.set_graph(g)\n",
        "\n",
        "        if self.adjoint_flag:\n",
        "            out = torchdiffeq.odeint_adjoint(self.odefunc, h, timestamps,\n",
        "                                             rtol=self.rtol, atol=self.atol, method=self.method)\n",
        "        else:\n",
        "            out = torchdiffeq.odeint(self.odefunc, h, timestamps,\n",
        "                                     rtol=self.rtol, atol=self.atol, method=self.method)\n",
        "\n",
        "        out = self._build_batch(out, nn, indices).reshape(h.shape)\n",
        "        return g, out\n",
        "    \n",
        "    def _build_batch(self, odeout, nn, indices):\n",
        "        b_out = []\n",
        "        for i in range(len(indices)):\n",
        "            b_out.append(odeout[indices[i],i*nn:(i+1)*nn])\n",
        "        return torch.cat(b_out).to(odeout.device)\n",
        "              \n",
        "        \n",
        "    def trajectory(self, x:torch.Tensor, T:int, num_points:int):\n",
        "        self.integration_time = torch.linspace(0, t_end, num_points)\n",
        "        self.integration_time = self.integration_time.type_as(x)\n",
        "        out = torchdiffeq.odeint(self.odefunc, x, self.integration_time,\n",
        "                                 rtol=self.rtol, atol=self.atol, method=self.method)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLs5RezsqnAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ODEModel(nn.Module):\n",
        "    def __init__(self, num_feats, n_classes):\n",
        "        # dim is edge number\n",
        "        super(ODEModel, self).__init__()\n",
        "        gnn = nn.Sequential(GCNLayer(in_feats=64, out_feats=64, activation=nn.Softplus(), dropout=0.9),\n",
        "                  GCNLayer(in_feats=64, out_feats=64, activation=None, dropout=0.9)\n",
        "                 ).to(DEVICE)\n",
        "\n",
        "        gdefunc = GDEFunc(gnn)\n",
        "        gde = ODEBlock(odefunc=gdefunc, method='rk4', atol=1e-3, rtol=1e-4, adjoint=False).to(DEVICE)\n",
        "        self.model = nn.Sequential(GCNLayer(in_feats=num_feats, out_feats=64, activation=F.relu, dropout=0.4),\n",
        "                  gde,\n",
        "                  GCNLayer(in_feats=64, out_feats=n_classes, activation=None, dropout=0.)\n",
        "                  ).to(DEVICE)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        g, h = inputs\n",
        "        return self.model((g, h)))[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU82B_9avthm",
        "colab_type": "text"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy6URULyvsZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, criterion, accuracy, lr_fn, meter_fn):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.accuracy = accuracy\n",
        "        self.lr_fn = lr_fn\n",
        "        self.batch_time_meter = meter_fn\n",
        "        self.f_nfe_meter = meter_fn\n",
        "        self.b_nfe_meter = meter_fn\n",
        "    \n",
        "    def run(self, epochs, train_dataloader, val_dataloader, test_dataloader):\n",
        "        train_size = train_dataloader.size\n",
        "        batches_per_eoch = train_size // train_dataloader.batchsize\n",
        "        for itr in range(epochs):\n",
        "            for batch_turn in range(batches_per_epoch):\n",
        "                x, y = train_dataloader.next()\n",
        "\n",
        "                nfe = self.model._modules['1'].odefunc.nfe\n",
        "\n",
        "                x = x.to(DEVICE)\n",
        "                y = y.to(DEVICE)\n",
        "                self.model.train()\n",
        "                logits = self.model(x)\n",
        "\n",
        "                result = logits.cpu().detach().numpy()\n",
        "                loss = self.criterion(logits, y)\n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                loss.backward()\n",
        "\n",
        "                self.optimizer.step()\n",
        "\n",
        "                print(\"[%d] Completed one batch\" % batch_turn)\n",
        "\n",
        "                #with train_summary_writer.as_default():\n",
        "                    #tensorflow.summary.scalar('loss', loss.item(), step=globaliter)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                self.model.eval()\n",
        "                train_acc = self.accuracy(self.model, test_dataloader)\n",
        "                val_acc = self.accuracy(self.model, val_dataloader)\n",
        "                print(\n",
        "                     \"Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | Train Acc {:.4f} | Test Acc {:.4f}\".format( itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg, b_nfe_meter.avg, train_acc, val_acc )\n",
        "                     )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um68hHB8yabg",
        "colab_type": "text"
      },
      "source": [
        "#Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV-Q0qxP52qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seed for repeatability\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "train_dataloader, test_dataloader, val_dataloader = train_val_test_split(batch_size=BATCH_SIZE, validation_ratio=0.1, test_ratio=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvmn0nFByljF",
        "colab_type": "text"
      },
      "source": [
        "#Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5rkG4aeJol2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ODEModel() #method is None\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "criterion = nn.MSELoss().to(DEVICE)\n",
        "batches_per_epoch = train_dataloader.size // train_dataloader.batchsize\n",
        "lr_fn = learning_rate_with_decay(\n",
        "        BATCH_SIZE, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\n",
        "        decay_rates=[1, 0.1, 0.01, 0.001]\n",
        ")\n",
        "trainer = Trainer(model=model,optimizer=optimizer,criterion=criterion,\n",
        "                  accuracy=accuracy,lr_fn=lr_fn,meter_fn=RunningAverageMeter())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV4dGU-o53u6",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb3aCXUKKurg",
        "colab_type": "code",
        "outputId": "ed9f165d-a211-4b8f-c5b1-853575e16bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#%tensorboard --logdir logs/tensorboard\n",
        "trainer.run(NEPOCHS, train_dataloader, val_dataloader, test_dataloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] Completed one batch\n",
            "[1] Completed one batch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clp_P7X85w9t",
        "colab_type": "text"
      },
      "source": [
        "# Predict input\n",
        "\n",
        "adjoint.py의 81번째 코드 참고!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njYhQpNy5v-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict x by y\n",
        "search_size = 1\n",
        "for itr in range(min(train_size, search_size)):\n",
        "    x,y = train_dataloader.next(1)\n",
        "    y = np.transpose(y.numpy())\n",
        "\n",
        "    # Linear\n",
        "    weight = model[5].weight\n",
        "    bias = model[5].bias.cpu().detach().numpy()\n",
        "    bias = bias.reshape((2,1))\n",
        "    z_tn = np.subtract(y, bias)\n",
        "    inverse_weight = np.linalg.pinv(weight.cpu().detach().numpy())\n",
        "    z_tn = np.matmul(inverse_weight, z_tn)\n",
        "\n",
        "    # AdaptiveAvgPool1d(1)\n",
        "    z_tn = np.repeat(z_tn, EMBED_SIZE, axis=1)\n",
        "    z_tn = np.expand_dims(z_tn, axis=0)\n",
        "\n",
        "    # ode back\n",
        "    z_tn = torch.from_numpy(z_tn).to(DEVICE)\n",
        "    z_t0 = odeint(ODEf, z_tn, torch.tensor([1, 0]).float().type_as(z_tn) , rtol=RTOL, atol=ATOL, method = 'adams')[1]\n",
        "    # output[0] is for time t0, output[1] is for time t1.\n",
        "\n",
        "    assert z_t0.shape == (1, 9,18)\n",
        "\n",
        "    z_t0 = z_t0.cpu().detach().numpy()\n",
        "    encoded = max_index(z_t0)\n",
        "    \n",
        "    print(\"encoded\")\n",
        "    for enc_ in encoded:\n",
        "        print(enc_)\n",
        "    \n",
        "    mat, op = decode(encoded)\n",
        "\n",
        "    print(\"mat\")\n",
        "    for mat_ in mat:\n",
        "        print(mat_)\n",
        "    print(\"y:\", y)\n",
        "\n",
        "\n",
        "    def __run_experiment(mat, op):\n",
        "        model_spec = api.ModelSpec(matrix=mat, ops=op)\n",
        "        q = nasbench_api.query(model_spec)\n",
        "        return q['validation_accuracy'], q['training_time']\n",
        "\n",
        "\n",
        "    print(\"result\", __run_experiment(mat, op))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}