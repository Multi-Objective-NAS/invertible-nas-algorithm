{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural ODE",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPT/u23ntVnWe9MlyNiPPl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Multi-Objective-NAS/invertible-nas-algorithm/blob/master/Neural_ODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0uTqCujPcZx",
        "colab_type": "text"
      },
      "source": [
        "#Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8mLWV7lPQLL",
        "colab_type": "code",
        "outputId": "40b85a21-3b6b-4bbd-8c0f-94e5d2fb0ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "pip install git+https://github.com/rtqichen/torchdiffeq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rtqichen/torchdiffeq\n",
            "  Cloning https://github.com/rtqichen/torchdiffeq to /tmp/pip-req-build-ff1m7g3y\n",
            "  Running command git clone -q https://github.com/rtqichen/torchdiffeq /tmp/pip-req-build-ff1m7g3y\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torchdiffeq==0.0.1) (1.4.0)\n",
            "Building wheels for collected packages: torchdiffeq\n",
            "  Building wheel for torchdiffeq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchdiffeq: filename=torchdiffeq-0.0.1-cp36-none-any.whl size=27578 sha256=9a56ea8a39e022cc6baf541e42c7547a303d0df6ae783b65642439f181931928\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dszomj05/wheels/3f/76/69/01867bf3355c3bc8bae7e556b17b44c395b6cda5e76fd8ddc7\n",
            "Successfully built torchdiffeq\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY6utA-AEDkP",
        "colab_type": "code",
        "outputId": "f95747f4-ed26-4de1-9f2c-f07f9d47cf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/rtqichen/torchdiffeq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'torchdiffeq'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects:   6% (1/15)\u001b[K\rremote: Counting objects:  13% (2/15)\u001b[K\rremote: Counting objects:  20% (3/15)\u001b[K\rremote: Counting objects:  26% (4/15)\u001b[K\rremote: Counting objects:  33% (5/15)\u001b[K\rremote: Counting objects:  40% (6/15)\u001b[K\rremote: Counting objects:  46% (7/15)\u001b[K\rremote: Counting objects:  53% (8/15)\u001b[K\rremote: Counting objects:  60% (9/15)\u001b[K\rremote: Counting objects:  66% (10/15)\u001b[K\rremote: Counting objects:  73% (11/15)\u001b[K\rremote: Counting objects:  80% (12/15)\u001b[K\rremote: Counting objects:  86% (13/15)\u001b[K\rremote: Counting objects:  93% (14/15)\u001b[K\rremote: Counting objects: 100% (15/15)\u001b[K\rremote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects:   7% (1/14)\u001b[K\rremote: Compressing objects:  14% (2/14)\u001b[K\rremote: Compressing objects:  21% (3/14)\u001b[K\rremote: Compressing objects:  28% (4/14)\u001b[K\rremote: Compressing objects:  35% (5/14)\u001b[K\rremote: Compressing objects:  42% (6/14)\u001b[K\rremote: Compressing objects:  50% (7/14)\u001b[K\rremote: Compressing objects:  57% (8/14)\u001b[K\rremote: Compressing objects:  64% (9/14)\u001b[K\rremote: Compressing objects:  71% (10/14)\u001b[K\rremote: Compressing objects:  78% (11/14)\u001b[K\rremote: Compressing objects:  85% (12/14)\u001b[K\rremote: Compressing objects:  92% (13/14)\u001b[K\rremote: Compressing objects: 100% (14/14)\u001b[K\rremote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "Receiving objects:   0% (1/229)   \rReceiving objects:   1% (3/229)   \rReceiving objects:   2% (5/229)   \rReceiving objects:   3% (7/229)   \rReceiving objects:   4% (10/229)   \rReceiving objects:   5% (12/229)   \rReceiving objects:   6% (14/229)   \rReceiving objects:   7% (17/229)   \rReceiving objects:   8% (19/229)   \rReceiving objects:   9% (21/229)   \rReceiving objects:  10% (23/229)   \rReceiving objects:  11% (26/229)   \rReceiving objects:  12% (28/229)   \rReceiving objects:  13% (30/229)   \rReceiving objects:  14% (33/229)   \rReceiving objects:  15% (35/229)   \rReceiving objects:  16% (37/229)   \rReceiving objects:  17% (39/229)   \rReceiving objects:  18% (42/229)   \rReceiving objects:  19% (44/229)   \rReceiving objects:  20% (46/229)   \rReceiving objects:  21% (49/229)   \rReceiving objects:  22% (51/229)   \rReceiving objects:  23% (53/229)   \rReceiving objects:  24% (55/229)   \rReceiving objects:  25% (58/229)   \rReceiving objects:  26% (60/229)   \rReceiving objects:  27% (62/229)   \rremote: Total 229 (delta 3), reused 4 (delta 1), pack-reused 214\u001b[K\n",
            "Receiving objects:  28% (65/229)   \rReceiving objects:  29% (67/229)   \rReceiving objects:  30% (69/229)   \rReceiving objects:  31% (71/229)   \rReceiving objects:  32% (74/229)   \rReceiving objects:  33% (76/229)   \rReceiving objects:  34% (78/229)   \rReceiving objects:  35% (81/229)   \rReceiving objects:  36% (83/229)   \rReceiving objects:  37% (85/229)   \rReceiving objects:  38% (88/229)   \rReceiving objects:  39% (90/229)   \rReceiving objects:  40% (92/229)   \rReceiving objects:  41% (94/229)   \rReceiving objects:  42% (97/229)   \rReceiving objects:  43% (99/229)   \rReceiving objects:  44% (101/229)   \rReceiving objects:  45% (104/229)   \rReceiving objects:  46% (106/229)   \rReceiving objects:  47% (108/229)   \rReceiving objects:  48% (110/229)   \rReceiving objects:  49% (113/229)   \rReceiving objects:  50% (115/229)   \rReceiving objects:  51% (117/229)   \rReceiving objects:  52% (120/229)   \rReceiving objects:  53% (122/229)   \rReceiving objects:  54% (124/229)   \rReceiving objects:  55% (126/229)   \rReceiving objects:  56% (129/229)   \rReceiving objects:  57% (131/229)   \rReceiving objects:  58% (133/229)   \rReceiving objects:  59% (136/229)   \rReceiving objects:  60% (138/229)   \rReceiving objects:  61% (140/229)   \rReceiving objects:  62% (142/229)   \rReceiving objects:  63% (145/229)   \rReceiving objects:  64% (147/229)   \rReceiving objects:  65% (149/229)   \rReceiving objects:  66% (152/229)   \rReceiving objects:  67% (154/229)   \rReceiving objects:  68% (156/229)   \rReceiving objects:  69% (159/229)   \rReceiving objects:  70% (161/229)   \rReceiving objects:  71% (163/229)   \rReceiving objects:  72% (165/229)   \rReceiving objects:  73% (168/229)   \rReceiving objects:  74% (170/229)   \rReceiving objects:  75% (172/229)   \rReceiving objects:  76% (175/229)   \rReceiving objects:  77% (177/229)   \rReceiving objects:  78% (179/229)   \rReceiving objects:  79% (181/229)   \rReceiving objects:  80% (184/229)   \rReceiving objects:  81% (186/229)   \rReceiving objects:  82% (188/229)   \rReceiving objects:  83% (191/229)   \rReceiving objects:  84% (193/229)   \rReceiving objects:  85% (195/229)   \rReceiving objects:  86% (197/229)   \rReceiving objects:  87% (200/229)   \rReceiving objects:  88% (202/229)   \rReceiving objects:  89% (204/229)   \rReceiving objects:  90% (207/229)   \rReceiving objects:  91% (209/229)   \rReceiving objects:  92% (211/229)   \rReceiving objects:  93% (213/229)   \rReceiving objects:  94% (216/229)   \rReceiving objects:  95% (218/229)   \rReceiving objects:  96% (220/229)   \rReceiving objects:  97% (223/229)   \rReceiving objects:  98% (225/229)   \rReceiving objects:  99% (227/229)   \rReceiving objects: 100% (229/229)   \rReceiving objects: 100% (229/229), 715.37 KiB | 14.90 MiB/s, done.\n",
            "Resolving deltas:   0% (0/100)   \rResolving deltas:   9% (9/100)   \rResolving deltas:  11% (11/100)   \rResolving deltas:  14% (14/100)   \rResolving deltas:  16% (16/100)   \rResolving deltas:  17% (17/100)   \rResolving deltas:  21% (21/100)   \rResolving deltas:  24% (24/100)   \rResolving deltas:  25% (25/100)   \rResolving deltas:  28% (28/100)   \rResolving deltas:  30% (30/100)   \rResolving deltas:  33% (33/100)   \rResolving deltas:  37% (37/100)   \rResolving deltas:  48% (48/100)   \rResolving deltas:  52% (52/100)   \rResolving deltas:  55% (55/100)   \rResolving deltas:  56% (56/100)   \rResolving deltas:  57% (57/100)   \rResolving deltas:  61% (61/100)   \rResolving deltas:  67% (67/100)   \rResolving deltas:  70% (70/100)   \rResolving deltas:  73% (73/100)   \rResolving deltas:  79% (79/100)   \rResolving deltas:  82% (82/100)   \rResolving deltas:  86% (86/100)   \rResolving deltas:  89% (89/100)   \rResolving deltas:  98% (98/100)   \rResolving deltas: 100% (100/100)   \rResolving deltas: 100% (100/100), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvSUB8hRR3_m",
        "colab_type": "text"
      },
      "source": [
        "#Installation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i06DFfXR22T",
        "colab_type": "code",
        "outputId": "a66a286c-abc2-4a78-de52-77bcb9768fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "#!curl -O https://storage.googleapis.com/nasbench/nasbench_full.tfrecord\n",
        "!curl -O https://storage.googleapis.com/nasbench/nasbench_only108.tfrecord\n",
        "# Clone and install the code and dependencies.\n",
        "\n",
        "!git clone https://github.com/google-research/nasbench\n",
        "#!pip install ./nasbench\n",
        "\n",
        "# Initialize the NASBench object which parses the raw data into memory (this\n",
        "# should only be run once as it takes up to a few minutes)."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  498M  100  498M    0     0   114M      0  0:00:04  0:00:04 --:--:--  114M\n",
            "Cloning into 'nasbench'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 96 (delta 0), reused 2 (delta 0), pack-reused 92\u001b[K\n",
            "Unpacking objects: 100% (96/96), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGWYcVzqR7u-",
        "colab_type": "text"
      },
      "source": [
        "#Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh6xZU7bPbmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJfb9TERKpPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchdiffeq import odeint_adjoint as odeint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6wHSd1hJP8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Main Argument\n",
        "'''\n",
        "DEVICE = torch.device('cuda:0')\n",
        "#DEVICE = torch.device('cpu')\n",
        "BATCH_SIZE = 50\n",
        "LR = 0.1\n",
        "NEPOCHS = 1\n",
        "RTOL = 1e-7\n",
        "ATOL = 1e-9\n",
        "EDGE_NUM = 9\n",
        "\n",
        "'''\n",
        "Data Set\n",
        "'''\n",
        "# Useful constants\n",
        "INPUT = 'input'\n",
        "OUTPUT = 'output'\n",
        "CONV3X3 = 'conv3x3-bn-relu'\n",
        "CONV1X1 = 'conv1x1-bn-relu'\n",
        "MAXPOOL3X3 = 'maxpool3x3'\n",
        "OUTPUT = 'output'\n",
        "NUM_VERTICES = 7\n",
        "MAX_EDGES = 9\n",
        "EDGE_SPOTS = NUM_VERTICES * (NUM_VERTICES - 1) / 2  # Upper triangular matrix\n",
        "OP_SPOTS = NUM_VERTICES - 2  # Input/output vertices are fixed\n",
        "ALLOWED_OPS = [CONV3X3, CONV1X1, MAXPOOL3X3, OUTPUT]\n",
        "ALLOWED_EDGES = [0, 1]  # Binary adjacency matrix\n",
        "EMBED_SIZE = 7 + 7 + len(ALLOWED_OPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GBGPrRvBqM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a3d06edf-d32c-417e-e252-a6e2e33e45a2"
      },
      "source": [
        "%cd nasbench\n",
        "%ls\n",
        "!pwd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/nasbench\n",
            "CONTRIBUTING.md  \u001b[0m\u001b[01;34mimages\u001b[0m/  \u001b[01;34mnasbench\u001b[0m/       README.md\n",
            "example.py       LICENSE  NASBench.ipynb  setup.py\n",
            "/content/nasbench\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuYD8SyyTcL_",
        "colab_type": "code",
        "outputId": "8b787326-2c78-4142-df8b-5ada1bbff898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "from nasbench import api\n",
        "#nasbench = api.NASBench('nasbench_full.tfrecord')\n",
        "\n",
        "%cd ..\n",
        "\n",
        "nasbench_api = api.NASBench('nasbench_only108.tfrecord')\n",
        "nasbench_hashkeys = nasbench_api.hash_iterator()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/nasbench/nasbench/lib/training_time.py:130: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nasbench/nasbench/lib/training_time.py:174: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nasbench/nasbench/lib/evaluate.py:30: The name tf.train.NanLossDuringTrainingError is deprecated. Please use tf.estimator.NanLossDuringTrainingError instead.\n",
            "\n",
            "/content\n",
            "Loading dataset from file... This may take a few minutes...\n",
            "WARNING:tensorflow:From /content/nasbench/nasbench/api.py:146: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "Loaded dataset in 45 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDVfj4D5SAbf",
        "colab_type": "text"
      },
      "source": [
        "#Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H16SkgkDTk0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(mat, ops):\n",
        "    def _sanity_check(idx1, opidx, idx2):\n",
        "        if idx1 not in range(7):\n",
        "            return False\n",
        "        if idx2 not in range(7):\n",
        "            return False\n",
        "        if opidx not in range(4):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    encoded = []\n",
        "    for inbound, outbound in zip(*np.array(mat).nonzero()):\n",
        "        op = ALLOWED_OPS.index(ops[outbound])\n",
        "        assert _sanity_check(inbound, op, outbound)\n",
        "\n",
        "        embed = [0] * EMBED_SIZE\n",
        "        embed[inbound] = 1\n",
        "        embed[7 + op] = 1\n",
        "        embed[7 + len(ALLOWED_OPS) + outbound] = 1\n",
        "\n",
        "        encoded.append(embed)\n",
        "\n",
        "    assert np.array(encoded).shape == (9, EMBED_SIZE)\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def max_index(output):\n",
        "    # (1, 9,18)\n",
        "    encoded = []\n",
        "    outputs = [output_ for output_ in output[0]]\n",
        "    \n",
        "    for output in outputs:\n",
        "        embed = [0 for _ in range(EMBED_SIZE)]\n",
        "        inbound, op, outbound = np.argmax(output[:7]), np.argmax(output[7:-7]), np.argmax(output[-7:])\n",
        "        embed[inbound] = 1\n",
        "        embed[7 + op] = 1\n",
        "        embed[7 + len(ALLOWED_OPS) + outbound] = 1\n",
        "        assert np.sum(np.array(embed)) == 3\n",
        "        encoded.append(embed)\n",
        "\n",
        "    assert np.array(encoded).shape == (9, EMBED_SIZE)\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def decode(encoded):\n",
        "    mat = np.zeros((7, 7))\n",
        "    ops = [INPUT] + [CONV3X3 for _ in range(5)] + [OUTPUT]\n",
        "\n",
        "    for embed in encoded:\n",
        "        inbound, op, outbound = np.nonzero(np.array(embed))[0]\n",
        "        op -= 7\n",
        "        outbound -= (7 + len(ALLOWED_OPS))\n",
        "        ops[outbound] = ALLOWED_OPS[op]\n",
        "        if inbound > outbound:\n",
        "            (inbound, outbound) = (outbound, inbound)\n",
        "        elif inbound == outbound:\n",
        "            continue\n",
        "        mat[inbound][outbound] = 1\n",
        "\n",
        "    return mat.tolist(), ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkpTwA027xVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert np.array([[1,2,3],[1,2,3]]).shape == (2,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxgUzP7CG4_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader(object):\n",
        "    def __init__(self, start, end):\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.cur = start\n",
        "\n",
        "    def __run_experiment(self, mat, op):\n",
        "        model_spec = api.ModelSpec(matrix=mat, ops=op)\n",
        "        q = nasbench_api.query(model_spec)\n",
        "        return q['validation_accuracy'], q['training_time']\n",
        "\n",
        "    def next(self, batchsize):\n",
        "        global nasbench_hashkeys\n",
        "\n",
        "        xset = []\n",
        "        yset = []\n",
        "        if self.cur == self.end:\n",
        "            self.cur = self.end\n",
        "        for idx in range(self.cur, min(self.cur + batchsize, self.end)):\n",
        "            hash_val = nasbench_hashkeys[idx]\n",
        "            fixed_stat, _ = nasbench_api.get_metrics_from_hash(hash_val)\n",
        "            mat, op = fixed_stat['module_adjacency'], fixed_stat['module_operations']\n",
        "            x = encode(mat, op)\n",
        "            y = self.__run_experiment(mat, op)\n",
        "            xset.append(x)\n",
        "            yset.append(y)\n",
        "        xset = torch.FloatTensor(xset)\n",
        "        yset = torch.FloatTensor(yset)\n",
        "        return xset, yset\n",
        "\n",
        "\n",
        "def train_val_test_split(batch_size=100, validation_ratio=0.1, test_ratio=0.1):\n",
        "    global nasbench_hashkeys\n",
        "\n",
        "    revised = []\n",
        "    for hash_val in nasbench_hashkeys:\n",
        "        fixed_stat, _ = nasbench_api.get_metrics_from_hash(hash_val)\n",
        "        mat, op = fixed_stat['module_adjacency'], fixed_stat['module_operations']\n",
        "        if np.sum(mat) == EDGE_NUM:\n",
        "            revised.append(hash_val)\n",
        "\n",
        "    total_size = (len(revised) // batch_size) * batch_size\n",
        "    nasbench_hashkeys = revised[: total_size]\n",
        "    val_size = int(total_size * validation_ratio)\n",
        "    test_size = int(total_size * test_ratio)\n",
        "\n",
        "    return DataLoader(val_size+test_size, total_size), DataLoader(0, val_size), DataLoader(val_size, val_size+test_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pJRxXyGPtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "def norm(dim):\n",
        "    return nn.GroupNorm( dim, dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r50bPVRngIPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConcatConv1d(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
        "        super(ConcatConv1d, self).__init__()\n",
        "        self._layer = nn.Conv1d(\n",
        "            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        tt = torch.ones_like(x[:, :1, :]) * t\n",
        "        ttx = torch.cat([tt, x], 1)\n",
        "        return self._layer(ttx)\n",
        "\n",
        "\n",
        "class ODEfunc(nn.Module):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(ODEfunc, self).__init__()\n",
        "        self.norm1 = norm(dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = ConcatConv1d(dim, dim, 3, 1, 1)\n",
        "        self.norm2 = norm(dim)\n",
        "        self.conv2 = ConcatConv1d(dim, dim, 3, 1, 1)\n",
        "        self.norm3 = norm(dim)\n",
        "        self.nfe = 0\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        out = self.norm1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(t, out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(t, out)\n",
        "        out = self.norm3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXc6zDI_SsoG",
        "colab_type": "code",
        "outputId": "6716e1d6-1ade-4f45-e3f7-b19d41bebfcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#test\n",
        "a = torch.ones(3, 2)\n",
        "b = torch.zeros(3, 3)\n",
        "torch.cat([a, b], dim=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40d1LnWER4zH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#T_series = torch.linspace(0., 25., 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_XXh0e5GdBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ODEBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, odefunc):\n",
        "        super(ODEBlock, self).__init__()\n",
        "        self.odefunc = odefunc\n",
        "        self.integration_time = torch.tensor([0, 1]).float()\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.integration_time = self.integration_time.type_as(x)\n",
        "        #batch_t = T_series[:x.shape[0]]\n",
        "        out = odeint(self.odefunc, x, self.integration_time , rtol=RTOL, atol=ATOL, method = 'adams')\n",
        "        return out[1]\n",
        "\n",
        "    @property\n",
        "    def nfe(self):\n",
        "        return self.odefunc.nfe\n",
        "\n",
        "    @nfe.setter\n",
        "    def nfe(self, value):\n",
        "        self.odefunc.nfe = value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83nFNskiGg8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
        "        ret = x.view(-1, shape)\n",
        "        return ret\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5opgvqcGqac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunningAverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, momentum=0.99):\n",
        "        self.momentum = momentum\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = None\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        if self.val is None:\n",
        "            self.avg = val\n",
        "        else:\n",
        "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
        "        self.val = val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC9wuSPnHw4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):\n",
        "    initial_learning_rate = LR * batch_size / batch_denom\n",
        "\n",
        "    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]\n",
        "    vals = [initial_learning_rate * decay for decay in decay_rates]\n",
        "\n",
        "    def learning_rate_fn(itr):\n",
        "        lt = [itr < b for b in boundaries] + [True]\n",
        "        i = np.argmax(lt)\n",
        "        return vals[i]\n",
        "\n",
        "    return learning_rate_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol-Bb4xdIEp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(model, dataloader):\n",
        "    datasize = dataloader.end - dataloader.start\n",
        "    x, y = dataloader.next(datasize)\n",
        "    x = torch.FloatTensor(x)\n",
        "    x = x.to(DEVICE)\n",
        "    y = y.numpy()\n",
        "    result = model(x).cpu().detach().numpy()\n",
        "    total_correct = np.sum(np.square(result - y))\n",
        "    return total_correct / datasize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZrD_tl5JNBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um68hHB8yabg",
        "colab_type": "text"
      },
      "source": [
        "#Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV-Q0qxP52qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader, test_dataloader, val_dataloader = train_val_test_split(batch_size=BATCH_SIZE, validation_ratio=0.1, test_ratio=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvmn0nFByljF",
        "colab_type": "text"
      },
      "source": [
        "#Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5rkG4aeJol2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 9 * EMBED_SIZE\n",
        "ODEf = ODEfunc(9)\n",
        "ODEb = ODEBlock(ODEf)\n",
        "feature_layers = [ODEb]\n",
        "fc_layers = [norm(9), nn.ReLU(inplace=True), nn.AdaptiveAvgPool1d(1), Flatten(), nn.Linear(9, 2)]\n",
        "model = nn.Sequential(*feature_layers, *fc_layers).to(DEVICE)\n",
        "\n",
        "criterion = nn.MSELoss().to(DEVICE)\n",
        "\n",
        "train_size = train_dataloader.end - train_dataloader.start\n",
        "batches_per_epoch = (train_size) // BATCH_SIZE\n",
        "\n",
        "lr_fn = learning_rate_with_decay(\n",
        "        BATCH_SIZE, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\n",
        "        decay_rates=[1, 0.1, 0.01, 0.001]\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "\n",
        "best_acc = 0\n",
        "batch_time_meter = RunningAverageMeter()\n",
        "f_nfe_meter = RunningAverageMeter()\n",
        "b_nfe_meter = RunningAverageMeter()\n",
        "end = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV4dGU-o53u6",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb3aCXUKKurg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "ee9e19b1-8b1c-4368-8284-356086a27b9f"
      },
      "source": [
        "for itr in range(NEPOCHS):\n",
        "    for batch_turn in range(batches_per_epoch):\n",
        "        x, y = train_dataloader.next(BATCH_SIZE)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr_fn(itr * batches_per_epoch + batch_turn)\n",
        "        optimizer.zero_grad()\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "        logits = model(x)\n",
        "        result = logits.cpu().detach().numpy()\n",
        "        loss = criterion(logits, y)\n",
        "        #print(\"[%d] Completed loss\" % batch_turn)\n",
        "        nfe_forward = feature_layers[0].nfe\n",
        "        feature_layers[0].nfe = 0\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(\"[%d] Completed backward\" % batch_turn)\n",
        "        nfe_backward = feature_layers[0].nfe\n",
        "        feature_layers[0].nfe = 0\n",
        "        batch_time_meter.update(time.time() - end)\n",
        "        f_nfe_meter.update(nfe_forward)\n",
        "        b_nfe_meter.update(nfe_backward)\n",
        "        end = time.time()\n",
        "        print(\"[%d] Completed one batch\" % batch_turn)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        train_acc = accuracy(model, test_dataloader)\n",
        "        val_acc = accuracy(model, val_dataloader)\n",
        "        #if val_acc > best_acc:\n",
        "                #torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))\n",
        "                #best_acc = val_acc\n",
        "        print(\n",
        "                \"Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | Train Acc {:.4f} | Test Acc {:.4f}\".format( itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg, b_nfe_meter.avg, train_acc, val_acc )\n",
        "            )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-acef121448c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-e135339475fd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#batch_t = T_series[:x.shape[0]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0modefunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration_time\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRTOL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mATOL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adams'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchdiffeq/_impl/adjoint.py\u001b[0m in \u001b[0;36modeint_adjoint\u001b[0;34m(func, y0, t, rtol, atol, method, options)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mflat_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOdeintAdjointMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchdiffeq/_impl/adjoint.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSOLVERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0msolution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchdiffeq/_impl/adams.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, final_t)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mfinal_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvcabm_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mfinal_t\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvcabm_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvcabm_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adaptive_adams_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvcabm_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mfinal_t\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvcabm_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvcabm_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchdiffeq/_impl/adams.py\u001b[0m in \u001b[0;36m_adaptive_adams_step\u001b[0;34m(self, vcabm_state, final_t)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Explicit predictor step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_and_explicit_phi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_phi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         p_next = tuple(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchdiffeq/_impl/adams.py\u001b[0m in \u001b[0;36mg_and_explicit_phi\u001b[0;34m(prev_t, next_t, implicit_phi, k)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mg_and_explicit_phi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplicit_phi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mcurr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_t\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprev_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clp_P7X85w9t",
        "colab_type": "text"
      },
      "source": [
        "# Predict input\n",
        "\n",
        "adjoint.py 81  !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njYhQpNy5v-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict x by y\n",
        "search_size = 1\n",
        "for itr in range(min(train_size, search_size)):\n",
        "    x,y = train_dataloader.next(1)\n",
        "    y = np.transpose(y.numpy())\n",
        "\n",
        "    # Linear\n",
        "    weight = model[5].weight\n",
        "    bias = model[5].bias.cpu().detach().numpy()\n",
        "    bias = bias.reshape((2,1))\n",
        "    z_tn = np.subtract(y, bias)\n",
        "    inverse_weight = np.linalg.pinv(weight.cpu().detach().numpy())\n",
        "    z_tn = np.matmul(inverse_weight, z_tn)\n",
        "\n",
        "    # AdaptiveAvgPool1d(1)\n",
        "    z_tn = np.repeat(z_tn, EMBED_SIZE, axis=1)\n",
        "    z_tn = np.expand_dims(z_tn, axis=0)\n",
        "\n",
        "    # ode back\n",
        "    z_tn = torch.from_numpy(z_tn).to(DEVICE)\n",
        "    z_t0 = odeint(ODEf, z_tn, torch.tensor([1, 0]).float().type_as(z_tn) , rtol=RTOL, atol=ATOL, method = 'adams')[1]\n",
        "    # output[0] is for time t0, output[1] is for time t1.\n",
        "\n",
        "    assert z_t0.shape == (1, 9,18)\n",
        "\n",
        "    z_t0 = z_t0.cpu().detach().numpy()\n",
        "    encoded = max_index(z_t0)\n",
        "    \n",
        "    print(\"encoded\")\n",
        "    for enc_ in encoded:\n",
        "        print(enc_)\n",
        "    \n",
        "    mat, op = decode(encoded)\n",
        "\n",
        "    print(\"mat\")\n",
        "    for mat_ in mat:\n",
        "        print(mat_)\n",
        "    print(\"y:\", y)\n",
        "\n",
        "\n",
        "    def __run_experiment(mat, op):\n",
        "        model_spec = api.ModelSpec(matrix=mat, ops=op)\n",
        "        q = nasbench_api.query(model_spec)\n",
        "        return q['validation_accuracy'], q['training_time']\n",
        "\n",
        "\n",
        "    print(\"result\", __run_experiment(mat, op))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}