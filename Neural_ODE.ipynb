{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural ODE_1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJvRNwDKK0etIBgbZeS2wo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Multi-Objective-NAS/invertible-nas-algorithm/blob/master/Neural_ODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0uTqCujPcZx",
        "colab_type": "text"
      },
      "source": [
        "#Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8mLWV7lPQLL",
        "colab_type": "code",
        "outputId": "42dd2219-33c2-4d67-a22e-75bd0eb733de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "pip install git+https://github.com/rtqichen/torchdiffeq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rtqichen/torchdiffeq\n",
            "  Cloning https://github.com/rtqichen/torchdiffeq to /tmp/pip-req-build-m3tothpt\n",
            "  Running command git clone -q https://github.com/rtqichen/torchdiffeq /tmp/pip-req-build-m3tothpt\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torchdiffeq==0.0.1) (1.4.0)\n",
            "Building wheels for collected packages: torchdiffeq\n",
            "  Building wheel for torchdiffeq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchdiffeq: filename=torchdiffeq-0.0.1-cp36-none-any.whl size=27578 sha256=11d6e7724a36aa22658c2cc634f8d34d077ef1ecea710dc31ba5effb22d82d8a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u00txpge/wheels/3f/76/69/01867bf3355c3bc8bae7e556b17b44c395b6cda5e76fd8ddc7\n",
            "Successfully built torchdiffeq\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY6utA-AEDkP",
        "colab_type": "code",
        "outputId": "f2bbc914-98d1-460b-f9f2-87dbcf82fa60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/rtqichen/torchdiffeq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'torchdiffeq'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects:   9% (1/11)\u001b[K\rremote: Compressing objects:  18% (2/11)\u001b[K\rremote: Compressing objects:  27% (3/11)\u001b[K\rremote: Compressing objects:  36% (4/11)\u001b[K\rremote: Compressing objects:  45% (5/11)\u001b[K\rremote: Compressing objects:  54% (6/11)\u001b[K\rremote: Compressing objects:  63% (7/11)\u001b[K\rremote: Compressing objects:  72% (8/11)\u001b[K\rremote: Compressing objects:  81% (9/11)\u001b[K\rremote: Compressing objects:  90% (10/11)\u001b[K\rremote: Compressing objects: 100% (11/11)\u001b[K\rremote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "Receiving objects:   0% (1/225)   \rReceiving objects:   1% (3/225)   \rReceiving objects:   2% (5/225)   \rReceiving objects:   3% (7/225)   \rReceiving objects:   4% (9/225)   \rReceiving objects:   5% (12/225)   \rReceiving objects:   6% (14/225)   \rReceiving objects:   7% (16/225)   \rReceiving objects:   8% (18/225)   \rReceiving objects:   9% (21/225)   \rReceiving objects:  10% (23/225)   \rReceiving objects:  11% (25/225)   \rReceiving objects:  12% (27/225)   \rReceiving objects:  13% (30/225)   \rReceiving objects:  14% (32/225)   \rReceiving objects:  15% (34/225)   \rReceiving objects:  16% (36/225)   \rReceiving objects:  17% (39/225)   \rReceiving objects:  18% (41/225)   \rReceiving objects:  19% (43/225)   \rReceiving objects:  20% (45/225)   \rReceiving objects:  21% (48/225)   \rReceiving objects:  22% (50/225)   \rReceiving objects:  23% (52/225)   \rReceiving objects:  24% (54/225)   \rReceiving objects:  25% (57/225)   \rReceiving objects:  26% (59/225)   \rReceiving objects:  27% (61/225)   \rremote: Total 225 (delta 2), reused 2 (delta 0), pack-reused 214\u001b[K\n",
            "Receiving objects:  28% (63/225)   \rReceiving objects:  29% (66/225)   \rReceiving objects:  30% (68/225)   \rReceiving objects:  31% (70/225)   \rReceiving objects:  32% (72/225)   \rReceiving objects:  33% (75/225)   \rReceiving objects:  34% (77/225)   \rReceiving objects:  35% (79/225)   \rReceiving objects:  36% (81/225)   \rReceiving objects:  37% (84/225)   \rReceiving objects:  38% (86/225)   \rReceiving objects:  39% (88/225)   \rReceiving objects:  40% (90/225)   \rReceiving objects:  41% (93/225)   \rReceiving objects:  42% (95/225)   \rReceiving objects:  43% (97/225)   \rReceiving objects:  44% (99/225)   \rReceiving objects:  45% (102/225)   \rReceiving objects:  46% (104/225)   \rReceiving objects:  47% (106/225)   \rReceiving objects:  48% (108/225)   \rReceiving objects:  49% (111/225)   \rReceiving objects:  50% (113/225)   \rReceiving objects:  51% (115/225)   \rReceiving objects:  52% (117/225)   \rReceiving objects:  53% (120/225)   \rReceiving objects:  54% (122/225)   \rReceiving objects:  55% (124/225)   \rReceiving objects:  56% (126/225)   \rReceiving objects:  57% (129/225)   \rReceiving objects:  58% (131/225)   \rReceiving objects:  59% (133/225)   \rReceiving objects:  60% (135/225)   \rReceiving objects:  61% (138/225)   \rReceiving objects:  62% (140/225)   \rReceiving objects:  63% (142/225)   \rReceiving objects:  64% (144/225)   \rReceiving objects:  65% (147/225)   \rReceiving objects:  66% (149/225)   \rReceiving objects:  67% (151/225)   \rReceiving objects:  68% (153/225)   \rReceiving objects:  69% (156/225)   \rReceiving objects:  70% (158/225)   \rReceiving objects:  71% (160/225)   \rReceiving objects:  72% (162/225)   \rReceiving objects:  73% (165/225)   \rReceiving objects:  74% (167/225)   \rReceiving objects:  75% (169/225)   \rReceiving objects:  76% (171/225)   \rReceiving objects:  77% (174/225)   \rReceiving objects:  78% (176/225)   \rReceiving objects:  79% (178/225)   \rReceiving objects:  80% (180/225)   \rReceiving objects:  81% (183/225)   \rReceiving objects:  82% (185/225)   \rReceiving objects:  83% (187/225)   \rReceiving objects:  84% (189/225)   \rReceiving objects:  85% (192/225)   \rReceiving objects:  86% (194/225)   \rReceiving objects:  87% (196/225)   \rReceiving objects:  88% (198/225)   \rReceiving objects:  89% (201/225)   \rReceiving objects:  90% (203/225)   \rReceiving objects:  91% (205/225)   \rReceiving objects:  92% (207/225)   \rReceiving objects:  93% (210/225)   \rReceiving objects:  94% (212/225)   \rReceiving objects:  95% (214/225)   \rReceiving objects:  96% (216/225)   \rReceiving objects:  97% (219/225)   \rReceiving objects:  98% (221/225)   \rReceiving objects:  99% (223/225)   \rReceiving objects: 100% (225/225)   \rReceiving objects: 100% (225/225), 712.88 KiB | 15.50 MiB/s, done.\n",
            "Resolving deltas:   0% (0/99)   \rResolving deltas:   9% (9/99)   \rResolving deltas:  11% (11/99)   \rResolving deltas:  14% (14/99)   \rResolving deltas:  17% (17/99)   \rResolving deltas:  18% (18/99)   \rResolving deltas:  22% (22/99)   \rResolving deltas:  23% (23/99)   \rResolving deltas:  26% (26/99)   \rResolving deltas:  27% (27/99)   \rResolving deltas:  32% (32/99)   \rResolving deltas:  33% (33/99)   \rResolving deltas:  43% (43/99)   \rResolving deltas:  48% (48/99)   \rResolving deltas:  51% (51/99)   \rResolving deltas:  55% (55/99)   \rResolving deltas:  57% (57/99)   \rResolving deltas:  60% (60/99)   \rResolving deltas:  68% (68/99)   \rResolving deltas:  69% (69/99)   \rResolving deltas:  72% (72/99)   \rResolving deltas:  78% (78/99)   \rResolving deltas:  81% (81/99)   \rResolving deltas:  86% (86/99)   \rResolving deltas:  97% (97/99)   \rResolving deltas: 100% (99/99)   \rResolving deltas: 100% (99/99), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFyeG4DJFG0H",
        "colab_type": "code",
        "outputId": "42d5bcc5-4be4-4bfd-cb1c-728cd1160d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "cd torchdiffeq/_impl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'torchdiffeq/_impl'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvSUB8hRR3_m",
        "colab_type": "text"
      },
      "source": [
        "#Installation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i06DFfXR22T",
        "colab_type": "code",
        "outputId": "42895497-e346-48df-c76a-70d6024a6ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "#!curl -O https://storage.googleapis.com/nasbench/nasbench_full.tfrecord\n",
        "!curl -O https://storage.googleapis.com/nasbench/nasbench_only108.tfrecord\n",
        "# Clone and install the code and dependencies.\n",
        "\n",
        "!git clone https://github.com/google-research/nasbench\n",
        "!pip install ./nasbench\n",
        "\n",
        "# Initialize the NASBench object which parses the raw data into memory (this\n",
        "# should only be run once as it takes up to a few minutes)."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  498M  100  498M    0     0  78.0M      0  0:00:06  0:00:06 --:--:-- 91.5M\n",
            "Cloning into 'nasbench'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 96 (delta 0), reused 2 (delta 0), pack-reused 92\u001b[K\n",
            "Unpacking objects: 100% (96/96), done.\n",
            "Processing ./nasbench\n",
            "Requirement already satisfied: tensorflow>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from nasbench==1.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.1.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (3.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.15.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.11.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.17.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.27.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.12.0->nasbench==1.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.12.0->nasbench==1.0) (45.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.12.0->nasbench==1.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.12.0->nasbench==1.0) (1.0.0)\n",
            "Building wheels for collected packages: nasbench\n",
            "  Building wheel for nasbench (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nasbench: filename=nasbench-1.0-cp36-none-any.whl size=46787 sha256=63873caefe040242d3a5aa9da8794caf7a9be09312985515fcb9a73a4ac4b534\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-85hhwt1m/wheels/4b/19/99/1d5fdfe30f8b16fab91e900808f4f7e5adc38e602c84970ad5\n",
            "Successfully built nasbench\n",
            "Installing collected packages: nasbench\n",
            "Successfully installed nasbench-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGWYcVzqR7u-",
        "colab_type": "text"
      },
      "source": [
        "#Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuWDllIqKdse",
        "colab_type": "code",
        "outputId": "8291dc46-8892-49c7-a646-d413fe3b4f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh6xZU7bPbmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJfb9TERKpPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchdiffeq import odeint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6wHSd1hJP8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# main argument\n",
        "#Device = torch.device('cuda:0')\n",
        "Device = torch.device('cpu')\n",
        "Is_odenet = True\n",
        "downsampling_method = 'conv'\n",
        "Batch_size = 50\n",
        "Lr = 0.1\n",
        "NEpochs = 1\n",
        "Rtol=1e-7\n",
        "Atol=1e-9\n",
        "Edge_num = 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuYD8SyyTcL_",
        "colab_type": "code",
        "outputId": "b9955721-2032-4c59-f94a-aa4848896020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "from nasbench import api\n",
        "#nasbench = api.NASBench('nasbench_full.tfrecord')\n",
        "nasbench = api.NASBench('nasbench_only108.tfrecord')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/lib/training_time.py:130: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/lib/training_time.py:174: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/lib/evaluate.py:30: The name tf.train.NanLossDuringTrainingError is deprecated. Please use tf.estimator.NanLossDuringTrainingError instead.\n",
            "\n",
            "Loading dataset from file... This may take a few minutes...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/api.py:146: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "Loaded dataset in 57 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGlWRNs2BSYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Useful constants\n",
        "INPUT = 'input'\n",
        "OUTPUT = 'output'\n",
        "CONV3X3 = 'conv3x3-bn-relu'\n",
        "CONV1X1 = 'conv1x1-bn-relu'\n",
        "MAXPOOL3X3 = 'maxpool3x3'\n",
        "OUTPUT = 'output'\n",
        "NUM_VERTICES = 7\n",
        "MAX_EDGES = 9\n",
        "EDGE_SPOTS = NUM_VERTICES * (NUM_VERTICES - 1) / 2  # Upper triangular matrix\n",
        "OP_SPOTS = NUM_VERTICES - 2  # Input/output vertices are fixed\n",
        "ALLOWED_OPS = [CONV3X3, CONV1X1, MAXPOOL3X3, OUTPUT]\n",
        "ALLOWED_EDGES = [0, 1]  # Binary adjacency matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJd_SZCSkwRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Embed_size = 7 + 7 + len(ALLOWED_OPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDVfj4D5SAbf",
        "colab_type": "text"
      },
      "source": [
        "#Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H16SkgkDTk0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(mat, ops):\n",
        "    def _sanity_check(idx1, opidx, idx2):\n",
        "        if idx1 not in range(7):\n",
        "            return False\n",
        "        if idx2 not in range(7):\n",
        "            return False\n",
        "        if opidx not in range(4):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    encoded = []\n",
        "    for inbound, outbound in zip(*np.array(mat).nonzero()):\n",
        "        op = ALLOWED_OPS.index(ops[outbound])\n",
        "        assert _sanity_check(inbound, op, outbound)\n",
        "\n",
        "        embed = [0] * (EMBED_SIZE)\n",
        "        embed[inbound] = 1\n",
        "        embed[7 + op] = 1\n",
        "        embed[7 + len(ALLOWED_OPS) + outbound] = 1\n",
        "\n",
        "        encoded.append(embed)\n",
        "\n",
        "    assert np.array(encoded).shape == (9, EMBED_SIZE)\n",
        "    return encoded\n",
        "\n",
        "def max_index(output):\n",
        "    def find_max_index(ls):\n",
        "        return ls.index(max(ls))\n",
        "\n",
        "    encoded = []\n",
        "    outputs = [output[i: i + EMBED_SIZE] for i in range(0,len(output), EMBED_SIZE)]\n",
        "    for output in outputs:\n",
        "        embed = [0 for _ in range(EMBED_SIZE)]\n",
        "        inbound, op, outbound = find_max_index(output[:7]), find_max_index(output[7:-7]), find_max_index(output[-7:])\n",
        "        embed[inbound] = 1\n",
        "        embed[7 + op] = 1\n",
        "        embed[7 + len(ALLOWED_OPS) + outbound] = 1\n",
        "        encoded += embed\n",
        "    \n",
        "    assert np.sum(np.array(encoded)) == 3\n",
        "    return encoded\n",
        "\n",
        "def decode(encoded):\n",
        "    mat = np.zeros((7,7))\n",
        "    op = [INPUT] + [CONV3X3 for _ in range(5)] + [OUTPUT]\n",
        "\n",
        "    outputs = [output[i: i + EMBED_SIZE] for i in range(0,len(output), EMBED_SIZE)]\n",
        "    for embed in outputs:\n",
        "        inbound, op, outbound = np.nonzero(np.array(embed))[0]\n",
        "        op -= 7\n",
        "        outbound -= (7+len(ALLOWED_OPS))\n",
        "        mat[inbound][outbound] = 1\n",
        "        op[outboung] = ALLOWED_OPS[op]\n",
        "    \n",
        "    return mat.tolist(), op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkpTwA027xVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert np.array([[1,2,3],[1,2,3]]).shape == (2,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxgUzP7CG4_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_loader: x = embedding code, y = (accuracy, latency)\n",
        "#return train_loader, test_loader, train_eval_loader\n",
        "def generate_data(batch_size=100, validation_ratio=0.1, test_ratio=0.1):\n",
        "    def run_experiment(mat, op):\n",
        "        model_spec = api.ModelSpec(matrix=mat, ops=op)\n",
        "        q = nasbench.query(model_spec)\n",
        "\n",
        "        return (q['validation_accuracy'], q['training_time'])\n",
        "    \n",
        "    def train_val_test_split(dataset):\n",
        "        random.shuffle(dataset)\n",
        "        total_size = (len(dataset) // batch_size) * batch_size\n",
        "        dataset = dataset[: total_size]\n",
        "        val_size = int(total_size * validation_ratio)\n",
        "        test_size = int(total_size * test_ratio)\n",
        "\n",
        "        val, dataset = dataset[:val_size], dataset[val_size:]\n",
        "        test, train = dataset[:test_size], dataset[test_size:]\n",
        "\n",
        "        return train, val, test\n",
        "    \n",
        "    def is_target_graph(mat, op):\n",
        "        return np.sum(mat) == Edge_num\n",
        "\n",
        "\n",
        "    # Find every possible graph\n",
        "    dataset = []\n",
        "    for hash_val in nasbench.hash_iterator():\n",
        "        fixed_stat, _ = nasbench.get_metrics_from_hash(hash_val)\n",
        "        mat, op = fixed_stat['module_adjacency'], fixed_stat['module_operations']\n",
        "        if is_target_graph(mat, op):\n",
        "            x = encode(mat, op)\n",
        "            y = run_experiment(mat, op)\n",
        "            dataset.append((x,y))\n",
        "\n",
        "    return train_val_test_split(dataset)\n",
        "\n",
        "def data_loader(dataset, batch_turn, size):\n",
        "    xset = []\n",
        "    yset = []\n",
        "    for x,y in dataset[size * batch_turn : size * batch_turn + size]:\n",
        "        xset.append(x)\n",
        "        yset.append(y)\n",
        "    xset = torch.FloatTensor(xset)\n",
        "    yset = torch.FloatTensor(yset)\n",
        "    return xset, yset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pJRxXyGPtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "def norm(dim):\n",
        "    return nn.GroupNorm(min(32, dim), dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r50bPVRngIPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConcatConv1d(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
        "        super(ConcatConv1d, self).__init__()\n",
        "        self._layer = nn.Conv1d(\n",
        "            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        tt = torch.ones_like(x[:, :1, :]) * t\n",
        "        ttx = torch.cat([tt, x], 1)\n",
        "        return self._layer(ttx)\n",
        "\n",
        "\n",
        "class ODEfunc(nn.Module):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(ODEfunc, self).__init__()\n",
        "        self.norm1 = norm(dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = ConcatConv1d(dim, dim, 3, 1, 1)\n",
        "        self.norm2 = norm(dim)\n",
        "        self.conv2 = ConcatConv1d(dim, dim, 3, 1, 1)\n",
        "        self.norm3 = norm(dim)\n",
        "        self.nfe = 0\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        out = self.norm1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(t, out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(t, out)\n",
        "        out = self.norm3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14T9Cq-FCKUb",
        "colab_type": "code",
        "outputId": "663fd447-8224-4584-8a19-370fcad9b370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "class ODEfunc(nn.Module):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(ODEfunc, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, 50),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(50, dim),\n",
        "        )\n",
        "        self.nfe = 0\n",
        "\n",
        "        for m in self.net.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
        "                nn.init.constant_(m.bias, val=0)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        return self.net(x)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass ODEfunc(nn.Module):\\n\\n    def __init__(self, dim):\\n        super(ODEfunc, self).__init__()\\n\\n        self.net = nn.Sequential(\\n            nn.Linear(dim, 50),\\n            nn.Tanh(),\\n            nn.Linear(50, dim),\\n        )\\n        self.nfe = 0\\n\\n        for m in self.net.modules():\\n            if isinstance(m, nn.Linear):\\n                nn.init.normal_(m.weight, mean=0, std=0.1)\\n                nn.init.constant_(m.bias, val=0)\\n\\n    def forward(self, t, x):\\n        self.nfe += 1\\n        return self.net(x)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXc6zDI_SsoG",
        "colab_type": "code",
        "outputId": "005c4b0a-71ca-46ba-d76e-b0678d1011ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#test\n",
        "a = torch.ones(3, 2)\n",
        "b = torch.zeros(3, 3)\n",
        "torch.cat([a, b], dim=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40d1LnWER4zH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#T_series = torch.linspace(0., 25., 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_XXh0e5GdBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ODEBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, odefunc):\n",
        "        super(ODEBlock, self).__init__()\n",
        "        self.odefunc = odefunc\n",
        "        self.integration_time = torch.tensor([0, 1]).float()\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.integration_time = self.integration_time.type_as(x)\n",
        "        #batch_t = T_series[:x.shape[0]]\n",
        "        out = odeint(self.odefunc, x, self.integration_time , rtol=Rtol, atol=Atol, method = 'adams')\n",
        "        return out[1]\n",
        "\n",
        "    @property\n",
        "    def nfe(self):\n",
        "        return self.odefunc.nfe\n",
        "\n",
        "    @nfe.setter\n",
        "    def nfe(self, value):\n",
        "        self.odefunc.nfe = value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83nFNskiGg8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
        "        ret = x.view(-1, shape)\n",
        "        return ret\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5opgvqcGqac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunningAverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, momentum=0.99):\n",
        "        self.momentum = momentum\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = None\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        if self.val is None:\n",
        "            self.avg = val\n",
        "        else:\n",
        "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
        "        self.val = val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC9wuSPnHw4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inf_generator(iterable):\n",
        "    \"\"\"Allows training with DataLoaders in a single infinite loop:\n",
        "        for i, (x, y) in enumerate(inf_generator(train_loader)):\n",
        "    \"\"\"\n",
        "    iterator = iterable.__iter__()\n",
        "    while True:\n",
        "        try:\n",
        "            yield iterator.__next__()\n",
        "        except StopIteration:\n",
        "            iterator = iterable.__iter__()\n",
        "\n",
        "\n",
        "def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):\n",
        "    initial_learning_rate = Lr * batch_size / batch_denom\n",
        "\n",
        "    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]\n",
        "    vals = [initial_learning_rate * decay for decay in decay_rates]\n",
        "\n",
        "    def learning_rate_fn(itr):\n",
        "        lt = [itr < b for b in boundaries] + [True]\n",
        "        i = np.argmax(lt)\n",
        "        return vals[i]\n",
        "\n",
        "    return learning_rate_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol-Bb4xdIEp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(model, dataset):\n",
        "    x,y = data_loader(dataset=dataset, batch_turn=0, size=len(dataset))\n",
        "    x = torch.FloatTensor(x)\n",
        "    x = x.to(Device)\n",
        "    y = y.numpy()\n",
        "    result = model(x).cpu().detach().numpy()\n",
        "    total_correct =  np.sum(np.square(result - y))\n",
        "    return total_correct / len(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZrD_tl5JNBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV-Q0qxP52qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset, test_dataset, train_eval_dataset = generate_data(Batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5rkG4aeJol2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 9 * (Embed_size)\n",
        "feature_layers = [ODEBlock(ODEfunc(9))]\n",
        "fc_layers = [Flatten(), nn.Linear(input_size, 2)]\n",
        "model = nn.Sequential(*feature_layers, *fc_layers).to(Device)\n",
        "\n",
        "criterion = nn.MSELoss().to(Device)\n",
        "\n",
        "batches_per_epoch = len(train_dataset) // Batch_size\n",
        "\n",
        "lr_fn = learning_rate_with_decay(\n",
        "        Batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\n",
        "        decay_rates=[1, 0.1, 0.01, 0.001]\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=Lr, momentum=0.9)\n",
        "\n",
        "best_acc = 0\n",
        "batch_time_meter = RunningAverageMeter()\n",
        "f_nfe_meter = RunningAverageMeter()\n",
        "b_nfe_meter = RunningAverageMeter()\n",
        "end = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV4dGU-o53u6",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb3aCXUKKurg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for itr in range(NEpochs):\n",
        "    for batch_turn in range(batches_per_epoch):\n",
        "        x,y = data_loader(dataset=train_dataset, batch_turn=batch_turn, size=Batch_size)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr_fn(itr)\n",
        "        optimizer.zero_grad()\n",
        "        x = x.to(Device)\n",
        "        y = y.to(Device)\n",
        "        logits = model(x)\n",
        "        result = logits.cpu().detach().numpy()\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        if Is_odenet:\n",
        "            nfe_forward = feature_layers[0].nfe\n",
        "            feature_layers[0].nfe = 0\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if Is_odenet:\n",
        "            nfe_backward = feature_layers[0].nfe\n",
        "            feature_layers[0].nfe = 0\n",
        "\n",
        "        batch_time_meter.update(time.time() - end)\n",
        "        if Is_odenet:\n",
        "            f_nfe_meter.update(nfe_forward)\n",
        "            b_nfe_meter.update(nfe_backward)\n",
        "        end = time.time()\n",
        "\n",
        "    random.shuffle(train_dataset)\n",
        "    with torch.no_grad():\n",
        "        train_acc = accuracy(model, train_eval_dataset)\n",
        "        val_acc = accuracy(model, test_dataset)\n",
        "        '''if val_acc > best_acc:\n",
        "                torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))\n",
        "                best_acc = val_acc\n",
        "            '''\n",
        "        print(\n",
        "                \"Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | Train Acc {:.4f} | Test Acc {:.4f}\".format( itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg, b_nfe_meter.avg, train_acc, val_acc )\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clp_P7X85w9t",
        "colab_type": "text"
      },
      "source": [
        "# Predict input\n",
        "\n",
        "adjoint.py의 81번째 코드 참고!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njYhQpNy5v-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict x by y"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}