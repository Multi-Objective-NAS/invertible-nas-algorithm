{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural ODE",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVSofOISc5TDztppwufg6O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Multi-Objective-NAS/invertible-nas-algorithm/blob/master/Neural_ODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0uTqCujPcZx",
        "colab_type": "text"
      },
      "source": [
        "#Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8mLWV7lPQLL",
        "colab_type": "code",
        "outputId": "46b3072a-d6f6-47bb-fa4f-bf514aa2de59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "pip install git+https://github.com/rtqichen/torchdiffeq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rtqichen/torchdiffeq\n",
            "  Cloning https://github.com/rtqichen/torchdiffeq to /tmp/pip-req-build-qf03fbd8\n",
            "  Running command git clone -q https://github.com/rtqichen/torchdiffeq /tmp/pip-req-build-qf03fbd8\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torchdiffeq==0.0.1) (1.4.0)\n",
            "Building wheels for collected packages: torchdiffeq\n",
            "  Building wheel for torchdiffeq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchdiffeq: filename=torchdiffeq-0.0.1-cp36-none-any.whl size=27578 sha256=51f3002e8292d0c7f33a40df24c21f8044eb7603094de1bd82eae7a303cfb57f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4qximjq/wheels/3f/76/69/01867bf3355c3bc8bae7e556b17b44c395b6cda5e76fd8ddc7\n",
            "Successfully built torchdiffeq\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY6utA-AEDkP",
        "colab_type": "code",
        "outputId": "b3ec8e30-1dc9-40b7-e00d-1929ac5826e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/rtqichen/torchdiffeq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'torchdiffeq'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects:   6% (1/15)\u001b[K\rremote: Counting objects:  13% (2/15)\u001b[K\rremote: Counting objects:  20% (3/15)\u001b[K\rremote: Counting objects:  26% (4/15)\u001b[K\rremote: Counting objects:  33% (5/15)\u001b[K\rremote: Counting objects:  40% (6/15)\u001b[K\rremote: Counting objects:  46% (7/15)\u001b[K\rremote: Counting objects:  53% (8/15)\u001b[K\rremote: Counting objects:  60% (9/15)\u001b[K\rremote: Counting objects:  66% (10/15)\u001b[K\rremote: Counting objects:  73% (11/15)\u001b[K\rremote: Counting objects:  80% (12/15)\u001b[K\rremote: Counting objects:  86% (13/15)\u001b[K\rremote: Counting objects:  93% (14/15)\u001b[K\rremote: Counting objects: 100% (15/15)\u001b[K\rremote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects:   7% (1/14)\u001b[K\rremote: Compressing objects:  14% (2/14)\u001b[K\rremote: Compressing objects:  21% (3/14)\u001b[K\rremote: Compressing objects:  28% (4/14)\u001b[K\rremote: Compressing objects:  35% (5/14)\u001b[K\rremote: Compressing objects:  42% (6/14)\u001b[K\rremote: Compressing objects:  50% (7/14)\u001b[K\rremote: Compressing objects:  57% (8/14)\u001b[K\rremote: Compressing objects:  64% (9/14)\u001b[K\rremote: Compressing objects:  71% (10/14)\u001b[K\rremote: Compressing objects:  78% (11/14)\u001b[K\rremote: Compressing objects:  85% (12/14)\u001b[K\rremote: Compressing objects:  92% (13/14)\u001b[K\rremote: Compressing objects: 100% (14/14)\u001b[K\rremote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "Receiving objects:   0% (1/229)   \rReceiving objects:   1% (3/229)   \rReceiving objects:   2% (5/229)   \rReceiving objects:   3% (7/229)   \rReceiving objects:   4% (10/229)   \rReceiving objects:   5% (12/229)   \rReceiving objects:   6% (14/229)   \rReceiving objects:   7% (17/229)   \rReceiving objects:   8% (19/229)   \rReceiving objects:   9% (21/229)   \rReceiving objects:  10% (23/229)   \rReceiving objects:  11% (26/229)   \rReceiving objects:  12% (28/229)   \rReceiving objects:  13% (30/229)   \rReceiving objects:  14% (33/229)   \rReceiving objects:  15% (35/229)   \rReceiving objects:  16% (37/229)   \rReceiving objects:  17% (39/229)   \rReceiving objects:  18% (42/229)   \rReceiving objects:  19% (44/229)   \rReceiving objects:  20% (46/229)   \rReceiving objects:  21% (49/229)   \rReceiving objects:  22% (51/229)   \rReceiving objects:  23% (53/229)   \rReceiving objects:  24% (55/229)   \rReceiving objects:  25% (58/229)   \rReceiving objects:  26% (60/229)   \rReceiving objects:  27% (62/229)   \rremote: Total 229 (delta 3), reused 4 (delta 1), pack-reused 214\u001b[K\n",
            "Receiving objects:  28% (65/229)   \rReceiving objects:  29% (67/229)   \rReceiving objects:  30% (69/229)   \rReceiving objects:  31% (71/229)   \rReceiving objects:  32% (74/229)   \rReceiving objects:  33% (76/229)   \rReceiving objects:  34% (78/229)   \rReceiving objects:  35% (81/229)   \rReceiving objects:  36% (83/229)   \rReceiving objects:  37% (85/229)   \rReceiving objects:  38% (88/229)   \rReceiving objects:  39% (90/229)   \rReceiving objects:  40% (92/229)   \rReceiving objects:  41% (94/229)   \rReceiving objects:  42% (97/229)   \rReceiving objects:  43% (99/229)   \rReceiving objects:  44% (101/229)   \rReceiving objects:  45% (104/229)   \rReceiving objects:  46% (106/229)   \rReceiving objects:  47% (108/229)   \rReceiving objects:  48% (110/229)   \rReceiving objects:  49% (113/229)   \rReceiving objects:  50% (115/229)   \rReceiving objects:  51% (117/229)   \rReceiving objects:  52% (120/229)   \rReceiving objects:  53% (122/229)   \rReceiving objects:  54% (124/229)   \rReceiving objects:  55% (126/229)   \rReceiving objects:  56% (129/229)   \rReceiving objects:  57% (131/229)   \rReceiving objects:  58% (133/229)   \rReceiving objects:  59% (136/229)   \rReceiving objects:  60% (138/229)   \rReceiving objects:  61% (140/229)   \rReceiving objects:  62% (142/229)   \rReceiving objects:  63% (145/229)   \rReceiving objects:  64% (147/229)   \rReceiving objects:  65% (149/229)   \rReceiving objects:  66% (152/229)   \rReceiving objects:  67% (154/229)   \rReceiving objects:  68% (156/229)   \rReceiving objects:  69% (159/229)   \rReceiving objects:  70% (161/229)   \rReceiving objects:  71% (163/229)   \rReceiving objects:  72% (165/229)   \rReceiving objects:  73% (168/229)   \rReceiving objects:  74% (170/229)   \rReceiving objects:  75% (172/229)   \rReceiving objects:  76% (175/229)   \rReceiving objects:  77% (177/229)   \rReceiving objects:  78% (179/229)   \rReceiving objects:  79% (181/229)   \rReceiving objects:  80% (184/229)   \rReceiving objects:  81% (186/229)   \rReceiving objects:  82% (188/229)   \rReceiving objects:  83% (191/229)   \rReceiving objects:  84% (193/229)   \rReceiving objects:  85% (195/229)   \rReceiving objects:  86% (197/229)   \rReceiving objects:  87% (200/229)   \rReceiving objects:  88% (202/229)   \rReceiving objects:  89% (204/229)   \rReceiving objects:  90% (207/229)   \rReceiving objects:  91% (209/229)   \rReceiving objects:  92% (211/229)   \rReceiving objects:  93% (213/229)   \rReceiving objects:  94% (216/229)   \rReceiving objects:  95% (218/229)   \rReceiving objects:  96% (220/229)   \rReceiving objects:  97% (223/229)   \rReceiving objects:  98% (225/229)   \rReceiving objects:  99% (227/229)   \rReceiving objects: 100% (229/229)   \rReceiving objects: 100% (229/229), 715.37 KiB | 2.28 MiB/s, done.\n",
            "Resolving deltas:   0% (0/100)   \rResolving deltas:   9% (9/100)   \rResolving deltas:  12% (12/100)   \rResolving deltas:  14% (14/100)   \rResolving deltas:  16% (16/100)   \rResolving deltas:  17% (17/100)   \rResolving deltas:  21% (21/100)   \rResolving deltas:  24% (24/100)   \rResolving deltas:  25% (25/100)   \rResolving deltas:  28% (28/100)   \rResolving deltas:  30% (30/100)   \rResolving deltas:  33% (33/100)   \rResolving deltas:  35% (35/100)   \rResolving deltas:  49% (49/100)   \rResolving deltas:  52% (52/100)   \rResolving deltas:  53% (53/100)   \rResolving deltas:  57% (57/100)   \rResolving deltas:  60% (60/100)   \rResolving deltas:  65% (65/100)   \rResolving deltas:  71% (71/100)   \rResolving deltas:  75% (75/100)   \rResolving deltas:  79% (79/100)   \rResolving deltas:  83% (83/100)   \rResolving deltas:  88% (88/100)   \rResolving deltas:  91% (91/100)   \rResolving deltas:  98% (98/100)   \rResolving deltas: 100% (100/100)   \rResolving deltas: 100% (100/100), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFyeG4DJFG0H",
        "colab_type": "code",
        "outputId": "251fb4ca-a84d-4b8d-a28f-bce3cb3e97b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "cd torchdiffeq/_impl"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'torchdiffeq/_impl'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvSUB8hRR3_m",
        "colab_type": "text"
      },
      "source": [
        "#Installation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i06DFfXR22T",
        "colab_type": "code",
        "outputId": "7ecfdffe-590f-4987-b4db-3285e728b752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "#!curl -O https://storage.googleapis.com/nasbench/nasbench_full.tfrecord\n",
        "!curl -O https://storage.googleapis.com/nasbench/nasbench_only108.tfrecord\n",
        "# Clone and install the code and dependencies.\n",
        "\n",
        "!git clone https://github.com/google-research/nasbench\n",
        "!pip install ./nasbench\n",
        "\n",
        "# Initialize the NASBench object which parses the raw data into memory (this\n",
        "# should only be run once as it takes up to a few minutes)."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  498M  100  498M    0     0  72.5M      0  0:00:06  0:00:06 --:--:-- 89.1M\n",
            "Cloning into 'nasbench'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 96 (delta 0), reused 2 (delta 0), pack-reused 92\u001b[K\n",
            "Unpacking objects: 100% (96/96), done.\n",
            "Processing ./nasbench\n",
            "Requirement already satisfied: tensorflow>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from nasbench==1.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.1.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (3.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.27.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.17.5)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.12.0->nasbench==1.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.12.0->nasbench==1.0) (45.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.12.0->nasbench==1.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.12.0->nasbench==1.0) (3.2.1)\n",
            "Building wheels for collected packages: nasbench\n",
            "  Building wheel for nasbench (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nasbench: filename=nasbench-1.0-cp36-none-any.whl size=46787 sha256=0311d6e67de808d176afc53573a7c93fbcbcf2f93ac29daa9eb96bcbb4258287\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8q9aj96k/wheels/4b/19/99/1d5fdfe30f8b16fab91e900808f4f7e5adc38e602c84970ad5\n",
            "Successfully built nasbench\n",
            "Installing collected packages: nasbench\n",
            "Successfully installed nasbench-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGWYcVzqR7u-",
        "colab_type": "text"
      },
      "source": [
        "#Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuWDllIqKdse",
        "colab_type": "code",
        "outputId": "d66f49bc-4c61-40a7-c801-00aac06568eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh6xZU7bPbmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJfb9TERKpPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchdiffeq import odeint_adjoint as odeint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6wHSd1hJP8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Main Argument\n",
        "'''\n",
        "DEVICE = torch.device('cuda:0')\n",
        "#DEVICE = torch.device('cpu')\n",
        "BATCH_SIZE = 50\n",
        "LR = 0.1\n",
        "NEPOCHS = 1\n",
        "RTOL = 1e-7\n",
        "ATOL = 1e-9\n",
        "EDGE_NUM = 9\n",
        "\n",
        "'''\n",
        "Data Set\n",
        "'''\n",
        "# Useful constants\n",
        "INPUT = 'input'\n",
        "OUTPUT = 'output'\n",
        "CONV3X3 = 'conv3x3-bn-relu'\n",
        "CONV1X1 = 'conv1x1-bn-relu'\n",
        "MAXPOOL3X3 = 'maxpool3x3'\n",
        "OUTPUT = 'output'\n",
        "NUM_VERTICES = 7\n",
        "MAX_EDGES = 9\n",
        "EDGE_SPOTS = NUM_VERTICES * (NUM_VERTICES - 1) / 2  # Upper triangular matrix\n",
        "OP_SPOTS = NUM_VERTICES - 2  # Input/output vertices are fixed\n",
        "ALLOWED_OPS = [CONV3X3, CONV1X1, MAXPOOL3X3, OUTPUT]\n",
        "ALLOWED_EDGES = [0, 1]  # Binary adjacency matrix\n",
        "EMBED_SIZE = 7 + 7 + len(ALLOWED_OPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuYD8SyyTcL_",
        "colab_type": "code",
        "outputId": "2f263fe2-659b-4c35-e42d-3df46fbb03a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "from nasbench import api\n",
        "#nasbench = api.NASBench('nasbench_full.tfrecord')\n",
        "nasbench_api = api.NASBench('nasbench_only108.tfrecord')\n",
        "nasbench_hashkeys = nasbench_api.hash_iterator()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/lib/training_time.py:130: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/lib/training_time.py:174: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/lib/evaluate.py:30: The name tf.train.NanLossDuringTrainingError is deprecated. Please use tf.estimator.NanLossDuringTrainingError instead.\n",
            "\n",
            "Loading dataset from file... This may take a few minutes...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/api.py:146: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "Loaded dataset in 47 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDVfj4D5SAbf",
        "colab_type": "text"
      },
      "source": [
        "#Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H16SkgkDTk0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(mat, ops):\n",
        "    def _sanity_check(idx1, opidx, idx2):\n",
        "        if idx1 not in range(7):\n",
        "            return False\n",
        "        if idx2 not in range(7):\n",
        "            return False\n",
        "        if opidx not in range(4):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    encoded = []\n",
        "    for inbound, outbound in zip(*np.array(mat).nonzero()):\n",
        "        op = ALLOWED_OPS.index(ops[outbound])\n",
        "        assert _sanity_check(inbound, op, outbound)\n",
        "\n",
        "        embed = [0] * EMBED_SIZE\n",
        "        embed[inbound] = 1\n",
        "        embed[7 + op] = 1\n",
        "        embed[7 + len(ALLOWED_OPS) + outbound] = 1\n",
        "\n",
        "        encoded.append(embed)\n",
        "\n",
        "    assert np.array(encoded).shape == (9, EMBED_SIZE)\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def max_index(output):\n",
        "    # (1, 9,18)\n",
        "    encoded = []\n",
        "    outputs = [output_ for output_ in output[0]]\n",
        "    \n",
        "    for output in outputs:\n",
        "        embed = [0 for _ in range(EMBED_SIZE)]\n",
        "        inbound, op, outbound = np.argmax(output[:7]), np.argmax(output[7:-7]), np.argmax(output[-7:])\n",
        "        embed[inbound] = 1\n",
        "        embed[7 + op] = 1\n",
        "        embed[7 + len(ALLOWED_OPS) + outbound] = 1\n",
        "        assert np.sum(np.array(embed)) == 3\n",
        "        encoded.append(embed)\n",
        "\n",
        "    assert np.array(encoded).shape == (9, EMBED_SIZE)\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def decode(encoded):\n",
        "    mat = np.zeros((7, 7))\n",
        "    ops = [INPUT] + [CONV3X3 for _ in range(5)] + [OUTPUT]\n",
        "\n",
        "    for embed in encoded:\n",
        "        inbound, op, outbound = np.nonzero(np.array(embed))[0]\n",
        "        op -= 7\n",
        "        outbound -= (7 + len(ALLOWED_OPS))\n",
        "        ops[outbound] = ALLOWED_OPS[op]\n",
        "        if inbound > outbound:\n",
        "            (inbound, outbound) = (outbound, inbound)\n",
        "        elif inbound == outbound:\n",
        "            continue\n",
        "        mat[inbound][outbound] = 1\n",
        "\n",
        "    return mat.tolist(), ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkpTwA027xVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert np.array([[1,2,3],[1,2,3]]).shape == (2,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxgUzP7CG4_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader(object):\n",
        "    def __init__(self, start, end):\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.cur = start\n",
        "\n",
        "    def __run_experiment(self, mat, op):\n",
        "        model_spec = api.ModelSpec(matrix=mat, ops=op)\n",
        "        q = nasbench_api.query(model_spec)\n",
        "        return q['validation_accuracy'], q['training_time']\n",
        "\n",
        "    def next(self, batchsize):\n",
        "        global nasbench_hashkeys\n",
        "\n",
        "        xset = []\n",
        "        yset = []\n",
        "        if self.cur == self.end:\n",
        "            self.cur = self.end\n",
        "        for idx in range(self.cur, min(self.cur + batchsize, self.end)):\n",
        "            hash_val = nasbench_hashkeys[idx]\n",
        "            fixed_stat, _ = nasbench_api.get_metrics_from_hash(hash_val)\n",
        "            mat, op = fixed_stat['module_adjacency'], fixed_stat['module_operations']\n",
        "            x = encode(mat, op)\n",
        "            y = self.__run_experiment(mat, op)\n",
        "            xset.append(x)\n",
        "            yset.append(y)\n",
        "        xset = torch.FloatTensor(xset)\n",
        "        yset = torch.FloatTensor(yset)\n",
        "        return xset, yset\n",
        "\n",
        "\n",
        "def train_val_test_split(batch_size=100, validation_ratio=0.1, test_ratio=0.1):\n",
        "    global nasbench_hashkeys\n",
        "\n",
        "    revised = []\n",
        "    for hash_val in nasbench_hashkeys:\n",
        "        fixed_stat, _ = nasbench_api.get_metrics_from_hash(hash_val)\n",
        "        mat, op = fixed_stat['module_adjacency'], fixed_stat['module_operations']\n",
        "        if np.sum(mat) == EDGE_NUM:\n",
        "            revised.append(hash_val)\n",
        "\n",
        "    total_size = (len(revised) // batch_size) * batch_size\n",
        "    nasbench_hashkeys = revised[: total_size]\n",
        "    val_size = int(total_size * validation_ratio)\n",
        "    test_size = int(total_size * test_ratio)\n",
        "\n",
        "    return DataLoader(val_size+test_size, total_size), DataLoader(0, val_size), DataLoader(val_size, val_size+test_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pJRxXyGPtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "def norm(dim):\n",
        "    return nn.GroupNorm( dim, dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r50bPVRngIPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConcatConv1d(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
        "        super(ConcatConv1d, self).__init__()\n",
        "        self._layer = nn.Conv1d(\n",
        "            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        tt = torch.ones_like(x[:, :1, :]) * t\n",
        "        ttx = torch.cat([tt, x], 1)\n",
        "        return self._layer(ttx)\n",
        "\n",
        "\n",
        "class ODEfunc(nn.Module):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(ODEfunc, self).__init__()\n",
        "        self.norm1 = norm(dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = ConcatConv1d(dim, dim, 3, 1, 1)\n",
        "        self.norm2 = norm(dim)\n",
        "        self.conv2 = ConcatConv1d(dim, dim, 3, 1, 1)\n",
        "        self.norm3 = norm(dim)\n",
        "        self.nfe = 0\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        out = self.norm1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(t, out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(t, out)\n",
        "        out = self.norm3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXc6zDI_SsoG",
        "colab_type": "code",
        "outputId": "b672fc93-4a6f-4d92-ea4c-b07fc3fcf6e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#test\n",
        "a = torch.ones(3, 2)\n",
        "b = torch.zeros(3, 3)\n",
        "torch.cat([a, b], dim=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40d1LnWER4zH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#T_series = torch.linspace(0., 25., 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_XXh0e5GdBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ODEBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, odefunc):\n",
        "        super(ODEBlock, self).__init__()\n",
        "        self.odefunc = odefunc\n",
        "        self.integration_time = torch.tensor([0, 1]).float()\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.integration_time = self.integration_time.type_as(x)\n",
        "        #batch_t = T_series[:x.shape[0]]\n",
        "        out = odeint(self.odefunc, x, self.integration_time , rtol=RTOL, atol=ATOL, method = 'adams')\n",
        "        return out[1]\n",
        "\n",
        "    @property\n",
        "    def nfe(self):\n",
        "        return self.odefunc.nfe\n",
        "\n",
        "    @nfe.setter\n",
        "    def nfe(self, value):\n",
        "        self.odefunc.nfe = value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83nFNskiGg8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
        "        ret = x.view(-1, shape)\n",
        "        return ret\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5opgvqcGqac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunningAverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, momentum=0.99):\n",
        "        self.momentum = momentum\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = None\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        if self.val is None:\n",
        "            self.avg = val\n",
        "        else:\n",
        "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
        "        self.val = val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC9wuSPnHw4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):\n",
        "    initial_learning_rate = LR * batch_size / batch_denom\n",
        "\n",
        "    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]\n",
        "    vals = [initial_learning_rate * decay for decay in decay_rates]\n",
        "\n",
        "    def learning_rate_fn(itr):\n",
        "        lt = [itr < b for b in boundaries] + [True]\n",
        "        i = np.argmax(lt)\n",
        "        return vals[i]\n",
        "\n",
        "    return learning_rate_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol-Bb4xdIEp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(model, dataloader):\n",
        "    datasize = dataloader.end - dataloader.start\n",
        "    x, y = dataloader.next(datasize)\n",
        "    x = torch.FloatTensor(x)\n",
        "    x = x.to(DEVICE)\n",
        "    y = y.numpy()\n",
        "    result = model(x).cpu().detach().numpy()\n",
        "    total_correct = np.sum(np.square(result - y))\n",
        "    return total_correct / datasize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZrD_tl5JNBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um68hHB8yabg",
        "colab_type": "text"
      },
      "source": [
        "#Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV-Q0qxP52qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader, test_dataloader, val_dataloader = train_val_test_split(batch_size=BATCH_SIZE, validation_ratio=0.1, test_ratio=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvmn0nFByljF",
        "colab_type": "text"
      },
      "source": [
        "#Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5rkG4aeJol2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 9 * EMBED_SIZE\n",
        "ODEf = ODEfunc(9)\n",
        "ODEb = ODEBlock(ODEf)\n",
        "feature_layers = [ODEb]\n",
        "fc_layers = [norm(9), nn.ReLU(inplace=True), nn.AdaptiveAvgPool1d(1), Flatten(), nn.Linear(9, 2)]\n",
        "model = nn.Sequential(*feature_layers, *fc_layers).to(DEVICE)\n",
        "\n",
        "criterion = nn.MSELoss().to(DEVICE)\n",
        "\n",
        "train_size = train_dataloader.end - train_dataloader.start\n",
        "batches_per_epoch = (train_size) // BATCH_SIZE\n",
        "\n",
        "lr_fn = learning_rate_with_decay(\n",
        "        BATCH_SIZE, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\n",
        "        decay_rates=[1, 0.1, 0.01, 0.001]\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "\n",
        "best_acc = 0\n",
        "batch_time_meter = RunningAverageMeter()\n",
        "f_nfe_meter = RunningAverageMeter()\n",
        "b_nfe_meter = RunningAverageMeter()\n",
        "end = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV4dGU-o53u6",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clp_P7X85w9t",
        "colab_type": "text"
      },
      "source": [
        "# Predict input\n",
        "\n",
        "adjoint.py의 81번째 코드 참고!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njYhQpNy5v-m",
        "colab_type": "code",
        "outputId": "0c303b80-a0bf-4dec-dea0-85b823b7fa86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "# predict x by y\n",
        "search_size = 1\n",
        "for itr in range(min(train_size, search_size)):\n",
        "    x,y = train_dataloader.next(1)\n",
        "    y = np.transpose(y.numpy())\n",
        "\n",
        "    # Linear\n",
        "    weight = model[5].weight\n",
        "    bias = model[5].bias.cpu().detach().numpy()\n",
        "    bias = bias.reshape((2,1))\n",
        "    z_tn = np.subtract(y, bias)\n",
        "    inverse_weight = np.linalg.pinv(weight.cpu().detach().numpy())\n",
        "    z_tn = np.matmul(inverse_weight, z_tn)\n",
        "\n",
        "    # AdaptiveAvgPool1d(1)\n",
        "    z_tn = np.repeat(z_tn, EMBED_SIZE, axis=1)\n",
        "    z_tn = np.expand_dims(z_tn, axis=0)\n",
        "\n",
        "    # ode back\n",
        "    z_tn = torch.from_numpy(z_tn).to(DEVICE)\n",
        "    z_t0 = odeint(ODEf, z_tn, torch.tensor([1, 0]).float().type_as(z_tn) , rtol=RTOL, atol=ATOL, method = 'adams')[1]\n",
        "    # output[0] is for time t0, output[1] is for time t1.\n",
        "\n",
        "    assert z_t0.shape == (1, 9,18)\n",
        "\n",
        "    z_t0 = z_t0.cpu().detach().numpy()\n",
        "    encoded = max_index(z_t0)\n",
        "    \n",
        "    print(\"encoded\")\n",
        "    for enc_ in encoded:\n",
        "        print(enc_)\n",
        "    \n",
        "    mat, op = decode(encoded)\n",
        "\n",
        "    print(\"mat\")\n",
        "    for mat_ in mat:\n",
        "        print(mat_)\n",
        "    print(\"y:\", y)\n",
        "\n",
        "\n",
        "    def __run_experiment(mat, op):\n",
        "        model_spec = api.ModelSpec(matrix=mat, ops=op)\n",
        "        q = nasbench_api.query(model_spec)\n",
        "        return q['validation_accuracy'], q['training_time']\n",
        "\n",
        "\n",
        "    print(\"result\", __run_experiment(mat, op))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoded\n",
            "[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "mat\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "y: [[8.6899036e-01]\n",
            " [1.3858979e+03]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OutOfDomainError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfDomainError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-73141a63f604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__run_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-73141a63f604>\u001b[0m in \u001b[0;36m__run_experiment\u001b[0;34m(mat, op)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__run_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mmodel_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnasbench_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nasbench/api.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, model_spec, epochs, stop_halfway)\u001b[0m\n\u001b[1;32m    235\u001b[0m                              % self.valid_epochs)\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mfixed_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputed_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0msampled_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_repeats'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mcomputed_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_stat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampled_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nasbench/api.py\u001b[0m in \u001b[0;36mget_metrics_from_spec\u001b[0;34m(self, model_spec)\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0mfixed\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomputed\u001b[0m \u001b[0mstats\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mspec\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0mmodule_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics_from_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nasbench/api.py\u001b[0m in \u001b[0;36m_check_spec\u001b[0;34m(self, model_spec)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;34m\"\"\"Checks that the model spec is within the dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_spec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mOutOfDomainError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid spec, provided graph is disconnected.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0mnum_vertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfDomainError\u001b[0m: invalid spec, provided graph is disconnected."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUVSd_Lrk5mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert 1 == 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb3aCXUKKurg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for itr in range(NEPOCHS):\n",
        "    for batch_turn in range(batches_per_epoch):\n",
        "        x, y = train_dataloader.next(BATCH_SIZE)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr_fn(itr * batches_per_epoch + batch_turn)\n",
        "        optimizer.zero_grad()\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "        logits = model(x)\n",
        "        result = logits.cpu().detach().numpy()\n",
        "        loss = criterion(logits, y)\n",
        "        print(\"[%d] Completed loss\" % batch_turn)\n",
        "        nfe_forward = feature_layers[0].nfe\n",
        "        feature_layers[0].nfe = 0\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(\"[%d] Completed backward\" % batch_turn)\n",
        "        nfe_backward = feature_layers[0].nfe\n",
        "        feature_layers[0].nfe = 0\n",
        "        batch_time_meter.update(time.time() - end)\n",
        "        f_nfe_meter.update(nfe_forward)\n",
        "        b_nfe_meter.update(nfe_backward)\n",
        "        end = time.time()\n",
        "        print(\"[%d] Completed one batch\" % batch_turn)\n",
        "\n",
        "'''\n",
        "    with torch.no_grad():\n",
        "        train_acc = accuracy(model, test_dataloader)\n",
        "        val_acc = accuracy(model, val_dataloader)\n",
        "            if val_acc > best_acc:\n",
        "                torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))\n",
        "                best_acc = val_acc\n",
        "        print(\n",
        "                \"Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | Train Acc {:.4f} | Test Acc {:.4f}\".format( itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg, b_nfe_meter.avg, train_acc, val_acc )\n",
        "            )\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibQqfhZwtpQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}