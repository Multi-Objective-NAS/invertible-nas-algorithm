{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural ODE의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9SVMYPhU/baDmtiOpiW0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Multi-Objective-NAS/invertible-nas-algorithm/blob/master/Neural_ODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0uTqCujPcZx",
        "colab_type": "text"
      },
      "source": [
        "#Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8mLWV7lPQLL",
        "colab_type": "code",
        "outputId": "286427f3-a007-437e-b3a5-84623badb691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "pip install git+https://github.com/rtqichen/torchdiffeq"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rtqichen/torchdiffeq\n",
            "  Cloning https://github.com/rtqichen/torchdiffeq to /tmp/pip-req-build-0x8w4l0q\n",
            "  Running command git clone -q https://github.com/rtqichen/torchdiffeq /tmp/pip-req-build-0x8w4l0q\n",
            "Requirement already satisfied (use --upgrade to upgrade): torchdiffeq==0.0.1 from git+https://github.com/rtqichen/torchdiffeq in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torchdiffeq==0.0.1) (1.4.0)\n",
            "Building wheels for collected packages: torchdiffeq\n",
            "  Building wheel for torchdiffeq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchdiffeq: filename=torchdiffeq-0.0.1-cp36-none-any.whl size=27578 sha256=ef58b071f770357d6aad906adc683898ca625bd85f168f07bd40e230e4d8d310\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qnn21__e/wheels/3f/76/69/01867bf3355c3bc8bae7e556b17b44c395b6cda5e76fd8ddc7\n",
            "Successfully built torchdiffeq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY6utA-AEDkP",
        "colab_type": "code",
        "outputId": "935cc982-cda2-4069-d30b-1f4ddd9ad6ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/rtqichen/torchdiffeq"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'torchdiffeq' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFyeG4DJFG0H",
        "colab_type": "code",
        "outputId": "2ae4c6ff-e0ff-419d-d911-c71524eb2d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "cd torchdiffeq/_impl"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'torchdiffeq/_impl'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvSUB8hRR3_m",
        "colab_type": "text"
      },
      "source": [
        "#Installation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i06DFfXR22T",
        "colab_type": "code",
        "outputId": "ba3f0d05-90ce-47c7-f297-2ec63b6ecdc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        }
      },
      "source": [
        "!curl -O https://storage.googleapis.com/nasbench/nasbench_full.tfrecord\n",
        "\n",
        "# Clone and install the code and dependencies.\n",
        "\n",
        "!git clone https://github.com/google-research/nasbench\n",
        "!pip install ./nasbench\n",
        "\n",
        "# Initialize the NASBench object which parses the raw data into memory (this\n",
        "# should only be run once as it takes up to a few minutes)."
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1989M  100 1989M    0     0  87.2M      0  0:00:22  0:00:22 --:--:-- 36.8M\n",
            "fatal: destination path 'nasbench' already exists and is not an empty directory.\n",
            "Processing ./nasbench\n",
            "Requirement already satisfied: tensorflow>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from nasbench==1.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.1.8)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.15.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.17.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.27.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.12.0->nasbench==1.0) (45.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.12.0->nasbench==1.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.12.0->nasbench==1.0) (1.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.12.0->nasbench==1.0) (2.8.0)\n",
            "Building wheels for collected packages: nasbench\n",
            "  Building wheel for nasbench (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nasbench: filename=nasbench-1.0-cp36-none-any.whl size=46787 sha256=94fb740ada75f8b3876c46acee5ec874bb8b7d351aadcbbda78348b613d6e59e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7sw9ua25/wheels/4b/19/99/1d5fdfe30f8b16fab91e900808f4f7e5adc38e602c84970ad5\n",
            "Successfully built nasbench\n",
            "Installing collected packages: nasbench\n",
            "  Found existing installation: nasbench 1.0\n",
            "    Uninstalling nasbench-1.0:\n",
            "      Successfully uninstalled nasbench-1.0\n",
            "Successfully installed nasbench-1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nasbench"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGWYcVzqR7u-",
        "colab_type": "text"
      },
      "source": [
        "#Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuWDllIqKdse",
        "colab_type": "code",
        "outputId": "f4d888a5-3580-4c6a-cc78-56eb57170006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh6xZU7bPbmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJfb9TERKpPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchdiffeq import odeint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6wHSd1hJP8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# main argument\n",
        "#device = torch.device('cuda:0')\n",
        "device = torch.device('cpu')\n",
        "is_odenet = True\n",
        "downsampling_method = 'conv'\n",
        "batch_size = 100\n",
        "lr = 0.1\n",
        "nepochs = 5\n",
        "rtol=1e-7\n",
        "atol=1e-9\n",
        "edge_num = 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuYD8SyyTcL_",
        "colab_type": "code",
        "outputId": "fc943c2f-d261-44d3-cdb2-29a219d149a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from nasbench import api\n",
        "nasbench = api.NASBench('nasbench_full.tfrecord')"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset from file... This may take a few minutes...\n",
            "Loaded dataset in 315 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGlWRNs2BSYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Useful constants\n",
        "INPUT = 'input'\n",
        "OUTPUT = 'output'\n",
        "CONV3X3 = 'conv3x3-bn-relu'\n",
        "CONV1X1 = 'conv1x1-bn-relu'\n",
        "MAXPOOL3X3 = 'maxpool3x3'\n",
        "OUTPUT = 'output'\n",
        "NUM_VERTICES = 7\n",
        "MAX_EDGES = 9\n",
        "EDGE_SPOTS = NUM_VERTICES * (NUM_VERTICES - 1) / 2  # Upper triangular matrix\n",
        "OP_SPOTS = NUM_VERTICES - 2  # Input/output vertices are fixed\n",
        "ALLOWED_OPS = [CONV3X3, CONV1X1, MAXPOOL3X3, OUTPUT]\n",
        "ALLOWED_EDGES = [0, 1]  # Binary adjacency matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDVfj4D5SAbf",
        "colab_type": "text"
      },
      "source": [
        "#Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pJRxXyGPtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "def norm(dim):\n",
        "    return nn.GroupNorm(min(32, dim), dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14T9Cq-FCKUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ODEfunc(nn.Module):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(ODEfunc, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, 50),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(50, dim),\n",
        "        )\n",
        "        self.nfe = 0\n",
        "\n",
        "        for m in self.net.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
        "                nn.init.constant_(m.bias, val=0)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_XXh0e5GdBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ODEBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, odefunc):\n",
        "        super(ODEBlock, self).__init__()\n",
        "        self.odefunc = odefunc\n",
        "        self.integration_time = torch.tensor([0, 1]).float()\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.integration_time = self.integration_time.type_as(x)\n",
        "        out = odeint(self.odefunc, x, self.integration_time, rtol=rtol, atol=atol)\n",
        "        return out[1]\n",
        "\n",
        "    @property\n",
        "    def nfe(self):\n",
        "        return self.odefunc.nfe\n",
        "\n",
        "    @nfe.setter\n",
        "    def nfe(self, value):\n",
        "        self.odefunc.nfe = value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgEv01jOF4V1",
        "colab_type": "text"
      },
      "source": [
        "##odeint\n",
        "dy/dt = func(t,y)\n",
        "\n",
        "y(t[0]) = y0 <- x\n",
        "\n",
        "method is None:\n",
        "\n",
        "solution = 'dopri5'.integrate(t)\n",
        "\n",
        "## integrate method\n",
        "* _assert_increasing(t)\n",
        "\n",
        "    * t must be increasing\n",
        "\n",
        "* before_integrate(t)\n",
        "\n",
        "    * _select_initial_step\n",
        "    * rk_state = _RungeKuttaState(y0, f0, t0, t0, first_step, )\n",
        "\n",
        "* Repeat as len(t):\n",
        "* solution <= advance(t[i])\n",
        "    * Until t > rk_state.t1:\n",
        "    * rk_state = _adaptive_dopri5_step(rk_state)\n",
        "    * Return, _interp_evaluate(rk_state.interp_coeff, rk_state.t0, rk_state.t1, next_t)\n",
        "\n",
        "## adaptive dopri5 step\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1xsQpgZB6DQ",
        "colab_type": "code",
        "outputId": "6489421d-cbbd-4de9-c44e-8687c2f51b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "integration_time = torch.tensor([0, 1]).float()\n",
        "print(integration_time)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83nFNskiGg8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
        "        return x.view(-1, shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5opgvqcGqac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunningAverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, momentum=0.99):\n",
        "        self.momentum = momentum\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = None\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        if self.val is None:\n",
        "            self.avg = val\n",
        "        else:\n",
        "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
        "        self.val = val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H16SkgkDTk0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(mat, ops):\n",
        "    def _sanity_check(idx1, opidx, idx2):\n",
        "        if idx1 not in range(7):\n",
        "            return False\n",
        "        if idx2 not in range(7):\n",
        "            return False\n",
        "        if opidx not in range(4):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    encoded = []\n",
        "    for inbound, outbound in zip(*np.array(mat).nonzero()):\n",
        "        op = ALLOWED_OPS.index(ops[outbound])\n",
        "        assert _sanity_check(inbound, op, outbound)\n",
        "\n",
        "        embed = [0] * (7 + 7 + len(ALLOWED_OPS))\n",
        "        embed[inbound] = 1\n",
        "        embed[7 + op] = 1\n",
        "        embed[7 + len(ALLOWED_OPS) + outbound] = 1\n",
        "\n",
        "        encoded += embed\n",
        "\n",
        "    assert len(encoded) == 9 * (7 + 7 + len(ALLOWED_OPS))\n",
        "    return encoded\n",
        "\n",
        "def max_index(output):\n",
        "    def find_max_index(ls):\n",
        "        return ls.index(max(ls))\n",
        "\n",
        "    encoded = []\n",
        "    embed_size = 7 + 7 + len(ALLOWED_OPS)\n",
        "    outputs = [output[i: i + embed_size] for i in range(0,len(output), embed_size)]\n",
        "    for output in outputs:\n",
        "        embed = [0 for _ in range(embed_size)]\n",
        "        inbound, op, outbound = find_max_index(output[:7]), find_max_index(output[7:-7]), find_max_index(output[-7:])\n",
        "        embed[inbound] = 1\n",
        "        embed[7 + op] = 1\n",
        "        embed[7 + len(ALLOWED_OPS) + outbound] = 1\n",
        "        encoded += embed\n",
        "    \n",
        "    assert np.sum(np.array(encoded)) == 3\n",
        "    return encoded\n",
        "\n",
        "def decode(encoded):\n",
        "    mat = np.zeros((7,7))\n",
        "    op = [INPUT] + [CONV3X3 for _ in range(5)] + [OUTPUT]\n",
        "\n",
        "    embed_size = 7 + 7 + len(ALLOWED_OPS)\n",
        "    outputs = [output[i: i + embed_size] for i in range(0,len(output), embed_size)]\n",
        "    for embed in outputs:\n",
        "        inbound, op, outbound = np.nonzero(np.array(embed))[0]\n",
        "        op -= 7\n",
        "        outbound -= (7+len(ALLOWED_OPS))\n",
        "        mat[inbound][outbound] = 1\n",
        "        op[outboung] = ALLOWED_OPS[op]\n",
        "    \n",
        "    return mat.tolist(), op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SjnDCqyMQrF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "558aa965-203d-4bd7-b3c0-ec5a763cd8d2"
      },
      "source": [
        "y = np.array([0,1,0,1,0])\n",
        "print(y, np.nonzero(y))\n",
        "a,b = np.nonzero(y)[0]\n",
        "print(a,b)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 1 0] (array([1, 3]),)\n",
            "1 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxgUzP7CG4_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_loader: x = embedding code, y = (accuracy, latency)\n",
        "#return train_loader, test_loader, train_eval_loader\n",
        "def generate_data(batch_size=100, validation_ratio=0.1, test_ratio=0.1):\n",
        "    def run_experiment(mat, op):\n",
        "        model_spec = api.ModelSpec(matrix=mat, ops=op)\n",
        "        q = nasbench.query(model_spec)\n",
        "\n",
        "        return (q['validation_accuracy'], q['training_time'])\n",
        "    \n",
        "    def train_val_test_split(dataset):\n",
        "        random.shuffle(dataset)\n",
        "        total_size = (len(dataset) // batch_size) * batch_size\n",
        "        dataset = dataset[: total_size]\n",
        "        val_size = int(total_size * validation_ratio)\n",
        "        test_size = int(total_size * test_ratio)\n",
        "\n",
        "        val, dataset = dataset[:val_size], dataset[val_size:]\n",
        "        test, train = dataset[:test_size], dataset[test_size:]\n",
        "\n",
        "        return train, val, test\n",
        "    \n",
        "    def is_target_graph(mat, op):\n",
        "        return np.sum(mat) == edge_num\n",
        "\n",
        "\n",
        "    # Find every possible graph\n",
        "    dataset = []\n",
        "    for hash_val in nasbench.hash_iterator():\n",
        "        fixed_stat, _ = nasbench.get_metrics_from_hash(hash_val)\n",
        "        mat, op = fixed_stat['module_adjacency'], fixed_stat['module_operations']\n",
        "        if is_target_graph(mat, op):\n",
        "            x = encode(mat, op)\n",
        "            y = run_experiment(mat, op)\n",
        "            dataset.append((x,y))\n",
        "\n",
        "    return train_val_test_split(dataset)\n",
        "\n",
        "def data_loader(dataset, batch_turn, size):\n",
        "    xset = []\n",
        "    yset = []\n",
        "    for x,y in dataset[size * batch_turn : size * batch_turn + size]:\n",
        "        xset.append(x)\n",
        "        yset.append(y)\n",
        "    xset = torch.FloatTensor(xset)\n",
        "    yset = torch.FloatTensor(yset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNWZykVyCTR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "7fe9d7f7-6316-440d-d0ca-5ecb4c052108"
      },
      "source": [
        "x = [100]\n",
        "y = (10,1)\n",
        "x = torch.FloatTensor(x)\n",
        "y = torch.FloatTensor(y)\n",
        "dataset = []\n",
        "dataset.append((x,y))\n",
        "print(dataset)\n",
        "print(dataset[0])"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-131-525c4c11aae2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    * x = [100]\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m starred assignment target must be in a list or tuple\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC9wuSPnHw4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inf_generator(iterable):\n",
        "    \"\"\"Allows training with DataLoaders in a single infinite loop:\n",
        "        for i, (x, y) in enumerate(inf_generator(train_loader)):\n",
        "    \"\"\"\n",
        "    iterator = iterable.__iter__()\n",
        "    while True:\n",
        "        try:\n",
        "            yield iterator.__next__()\n",
        "        except StopIteration:\n",
        "            iterator = iterable.__iter__()\n",
        "\n",
        "\n",
        "def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):\n",
        "    initial_learning_rate = lr * batch_size / batch_denom\n",
        "\n",
        "    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]\n",
        "    vals = [initial_learning_rate * decay for decay in decay_rates]\n",
        "\n",
        "    def learning_rate_fn(itr):\n",
        "        lt = [itr < b for b in boundaries] + [True]\n",
        "        i = np.argmax(lt)\n",
        "        return vals[i]\n",
        "\n",
        "    return learning_rate_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol-Bb4xdIEp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(model, dataset):\n",
        "    total_correct = 0\n",
        "    x,y = data_loader(dataset=dataset, batch_turn=0, size=len(dataset))\n",
        "    x = torch.FloatTensor(x)\n",
        "    x = x.to(device)\n",
        "    y = y.numpy()\n",
        "    total_correct +=  np.sum(np.square(model(x).cpu().detach().numpy() - y))\n",
        "    return total_correct / len(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsYRJBrPOjnu",
        "colab_type": "code",
        "outputId": "36ad60a3-3582-48e8-94b3-54a2af6822e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "a = np.array([1.0, 5.0])\n",
        "b = np.array([2.0, 4.0])\n",
        "ans = np.sum(np.square(a-b))\n",
        "print(ans)\n",
        "'''"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\na = np.array([1.0, 5.0])\\nb = np.array([2.0, 4.0])\\nans = np.sum(np.square(a-b))\\nprint(ans)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZrD_tl5JNBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si_A9sM9J5Qh",
        "colab_type": "code",
        "outputId": "54970513-a9a1-4b41-bad0-70884cc1cc21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb 19 11:13:22 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    29W / 149W |     11MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV-Q0qxP52qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " if downsampling_method == 'conv':\n",
        "        downsampling_layers = [\n",
        "            nn.Conv2d(1, 64, 3, 1),\n",
        "            norm(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 4, 2, 1),\n",
        "            norm(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 4, 2, 1),\n",
        "        ]\n",
        "elif downsampling_method == 'res':\n",
        "        downsampling_layers = [\n",
        "            nn.Conv2d(1, 64, 3, 1),\n",
        "            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n",
        "            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n",
        "        ]\n",
        "\n",
        "train_dataset, test_dataset, train_eval_dataset = generate_data(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5rkG4aeJol2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 9 * (7 + 7 + len(ALLOWED_OPS))\n",
        "feature_layers = [ODEBlock(ODEfunc(input_size))]\n",
        "fc_layers = [nn.Linear(input_size, 2)]\n",
        "model = nn.Sequential(*feature_layers, *fc_layers).to(device)\n",
        "\n",
        "criterion = nn.MSELoss().to(device)\n",
        "\n",
        "batches_per_epoch = len(train_dataset) // batch_size\n",
        "\n",
        "lr_fn = learning_rate_with_decay(\n",
        "        batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\n",
        "        decay_rates=[1, 0.1, 0.01, 0.001]\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "best_acc = 0\n",
        "batch_time_meter = RunningAverageMeter()\n",
        "f_nfe_meter = RunningAverageMeter()\n",
        "b_nfe_meter = RunningAverageMeter()\n",
        "end = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV4dGU-o53u6",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb3aCXUKKurg",
        "colab_type": "code",
        "outputId": "416c5029-7742-4d8b-b780-088ce4aa0fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "for itr in range(nepochs):\n",
        "    for batch_turn in range(batches_per_epoch):\n",
        "        x,y = batch_data_loader(dataset=train_dataset, batch_turn=batch_turn, size=batch_size)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr_fn(itr)\n",
        "        optimizer.zero_grad()\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        if is_odenet:\n",
        "            nfe_forward = feature_layers[0].nfe\n",
        "            feature_layers[0].nfe = 0\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if is_odenet:\n",
        "            nfe_backward = feature_layers[0].nfe\n",
        "            feature_layers[0].nfe = 0\n",
        "\n",
        "        batch_time_meter.update(time.time() - end)\n",
        "        if is_odenet:\n",
        "            f_nfe_meter.update(nfe_forward)\n",
        "            b_nfe_meter.update(nfe_backward)\n",
        "        end = time.time()\n",
        "\n",
        "    batch_num = 0\n",
        "    random.shuffle(train_dataset)\n",
        "    with torch.no_grad():\n",
        "        train_acc = accuracy(model, train_eval_dataset)\n",
        "        val_acc = accuracy(model, test_dataset)\n",
        "        '''if val_acc > best_acc:\n",
        "                torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))\n",
        "                best_acc = val_acc\n",
        "            '''\n",
        "        print(\n",
        "                \"Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | \"\n",
        "                Train Acc {:.4f} | Test Acc {:.4f}\".format(\n",
        "                itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg,\n",
        "                b_nfe_meter.avg, train_acc, val_acc\n",
        "            )"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-139-92a5063ffae9>\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    Train Acc {:.4f} | Test Acc {:.4f}\".format(\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clp_P7X85w9t",
        "colab_type": "text"
      },
      "source": [
        "# Predict input\n",
        "\n",
        "adjoint.py의 81번째 코드 참고!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njYhQpNy5v-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict x by y"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}